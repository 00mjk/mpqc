%
% $Log$
% Revision 1.12  1995/04/24 18:37:01  cljanss
% Port to xlC 2.1.3.
%
% Revision 1.11  1995/03/18  00:11:02  cljanss
% Using util/group to provide picl support.  Deleted the comm directory.
%
% Revision 1.10  1995/03/17  01:50:12  cljanss
% Removed -I. and -I$(SRCDIR) from the default include path in
% GlobalMakefile to avoid name conflicts with system include files.
% Modified files under src.lib to include all files relative to src.lib.
% Makefiles under src.bin need to add the -I. and -I$(SRCDIR) back onto
% INCLUDE and CXXINCLUDE or make other arrangements.
%
% Revision 1.9  1994/10/21  20:47:12  cljanss
% Allow sizeof(void*) != sizeof(int).
%
% Revision 1.8  1994/09/24  01:45:08  cljanss
% A few cleanups and made it work with cweave from cweb-3.1 and tex.
%
% Revision 1.7  1994/09/01  18:42:24  cljanss
% Changed bool type to booln to avoid conflict with the C++ builtin 'bool'.
%
% Revision 1.6  1994/08/26  21:03:14  etseidl
% fix some warnings
%
% Revision 1.5  1994/08/16  19:53:15  etseidl
% fix small bug with null costvec
%
% Revision 1.4  1994/05/17  15:33:14  etseidl
% change the way blocks are distributed by dmt_def_map2().  dmt_def_map2 now
% takes a cost struct rather than an int array
%
% Revision 1.3  1994/02/23  02:19:24  cljanss
% Converted from spiderweb to cweb.
%
% Revision 1.2  1993/12/30  13:18:39  etseidl
% merge in clj diffs
%
% Revision 1.13  1993/04/27  21:58:45  jannsen
% Port to RS/6000.  Minor bug fixes other minor things.
%
% Revision 1.12  1992/06/17  21:45:48  jannsen
% cleaned up for saber-c and removed unnecessary code
%
% Revision 1.11  1992/06/02  14:09:33  seidl
% change how blocks are parcelled out in dmt_def_map2()
%
% Revision 1.10  1992/06/01  23:18:41  jannsen
% upper bound on ngl_loop_id has been reduced to avoid message type conflicts
%
% Revision 1.9  1992/05/26  20:13:55  jannsen
% use mtype_get for libutil for message types
%
% Revision 1.8  1992/05/04  10:53:31  seidl
% fix dmt_map_examine, messages were getting crossed,
% also add flag to dmt_def_map2 to decide whether to select for size of a block
% or to use the passed in costvec
%
% Revision 1.7  1992/04/16  18:08:31  seidl
% changed dmt_def_map2
%
% Revision 1.6  1992/04/16  00:39:31  jannsen
% Changed the way that throttle works and added sync_loop.
%
% Revision 1.5  1992/04/08  00:50:29  jannsen
% fixed a bug that caused garbage to be written to "%a" data in
% dmt_next_gen_loop.
%
% Revision 1.4  1992/04/06  12:29:48  seidl
% merge in sandia changes
%
% Revision 1.3  1992/03/30  22:50:17  jannsen
% Merged in Sandia non CVS codes.
%
% Revision 1.11  1992/03/25  02:17:07  cljanss
% The synchronization for the old loop routines has been fixed and seems
% to work.  If the loop routines are not used as intended, then deadlock
% will occur with these modifications.
%
% Revision 1.10  1992/03/24  23:09:38  cljanss
% 1. Put in directives for the 'tmpl' prototyping facility.
% 2. Put in dmt_map_examine.
% 3. Put in nested general loop routines.
% 4. Increment send and receive message types in old loop routines.
% 5. Put in loop synchronization to avoid filling up system communication
%    buffers.  This doesn't work when N > Nproc for the old loop routines.
%    (This checkin is to entirely replace the old loop routines.)
% 6. Various other small changes-spelling corrections, etc.
%
% Revision 1.9  1992/03/12  21:10:55  cljanss
% added a routine to see how sparse a matrix is
%
% Revision 1.8  1992/03/11  19:03:16  cljanss
% corrected the declaration of static functions for ANSI C
%
% Revision 1.7  1992/03/11  18:54:23  cljanss
% merged Ed's new version with the changes from my previous check-in.
%
% Revision 1.5  1992/02/26  13:06:07  seidl
% include unistd.h on intel
%
% Revision 1.4  1992/02/20  15:21:04  seidl
% add general loop routines
%
% Revision 1.3  1992/01/22  17:39:03  seidl
% fix rcsid
%
% Revision 1.2  1992/01/22  15:45:23  seidl
% add rcs stuff
%
%
\def\narrower{\advance\leftskip by 20pt \advance\rightskip by 20pt}
\def\topofcontents{\centerline
    {\titlefont {\ttitlefont dmt\_pack}: A loop-distributed matrix manager.}\\
   {\bf Michael E. Colvin}\\
   {\bf Charles Tong} \\
   {\bf Curtis L. Janssen}\\
   {\bf Robert A. Whiteside}\\
   {\it Center for Computational Engineering}\\
   {\it Sandia National Laboratories, Livermore, CA} \\
   {\bf and}\\
   {\bf Edward T. Seidl}\\
   {\it National Institutes of Health}
\vfill}


\def\webtitle{\.{dmt\_pack}: A loop-distributed matrix manager.}

\def\botofcontents{\vfill
%\centerline{\bf Disclaimer}

%\begin{quotation}
%
%Copyright \copyright\ 1991, Sandia Corporation. The U.S. Government retains
%a limited license in this software.
%
%The U.S. Government retains, in this software, a paid-up,
%nonexclusive, irrevocable worldwide license to reproduce, prepare
%derivative works, perform publicly and display publicly by or for the
%Government, including the right to distribute to other Government
%contractors. 
%
%Neither the United States, the U.S. Dept. of Energy, nor any of their
%employees, makes any warranty, express or implied, or assumes any
%legal liability or responsibility for the accuracy, completeness, or
%usefulness of any information, apparatus, product, or product
%disclosed, or represents that its use would not infringe privately
%owned rights. 
%
%Export Controlled. Not to be exported outside the U.S. and Canada
%without prior approval of the Bureau of Export Administration, U.S.
%Department of Commerce.
%\end{quotation}
}

@* Introduction.  This is a package for the
manipulation of 2-dimensional arrays.  It provides for
dynamic creation and destruction of arrays, and for
numerous operations on these arrays.  Although the
operations provided for the arrays are those that I
needed for the implementation of a quantum chemistry
program, I hope that this will be generally useful.

The package supports two distribution schemes for
matrices: {\it columns} and {\it scattered.} In the
{\it column} distrbution of an $n \times n$ matrix over
$p$ processors, each processor gets at least
$\left\lfloor{n/p}\right\rfloor$ columns.  The first
$(n \bmod p)$ processors each have an extra column.
The assigmnemt of columns to processors is done
sequentially: node zero takes the first few columns,
node 1 takes the next few, {\it etc.} In this
distribution scheme matrix symmetry is not utilized,
since each node holds a complete column.

The {\it scattered} distribution scheme is only
available for symmetric matrices.  In this scheme, the
matrix is first divided into sub-matrices, or blocks,
based upon a map giving the size of each block.  I
expect that the blocks correspond to the shells in a
quantum chemistry computation. The upper triangle of
blocks is then distributed among the nodes.  The
current distribution scheme for these blocks is that
each processor takes every $p^{th}$ block in the upper
triangle.  My hope is that this usually results in
acceptable load balancing.  Note that in the scattered
block distribution, there are diagonal blocks. These
are held as the full block, thus there are some
redundant elements stored.  It is the responsibility of
the user to to the proper thing (whatever that is) with
these diagonal blocks.

Matrices in either form may be arranged into a
communications loop.  The programmer's interface to
this loop is simply to get the next available cell
(column or block) from one neighbor, possibly use or
modify it, and send that cell to the other neighbor.
The caller must assure, however, that any message sent
({\it via} one of these loop routines) is eventually
"gotten" by someone to remove the message from the
system.  Otherwise, the column or block may remain in
some system buffer leading to unpredictable results.
For the scattered block distribution, the system does
some buffering so that the cells used by the programmer
may be small, if that is convenient, but the messages
actually transferred are large for better performance.


@ RCS information

@c
static char rcsid[] = "$Id$";

@ Some pre-processor definitions control conditional
compilation.  |STRIPDOWN| removes everything not used
by the SCF program, and everything inappropriate for an
actual parallel processor. Defining this includes much
stuff useful for debugging, as well as for computations
other that SCF.

@c
#undef STRIPDOWN

@ There is a test main program provided in the file.
Define |TESTING| to include it.

@c
#undef TESTING

@ On the NCUBE we don't wnat to have the debug stuff 
around since it doesn't work anyway.

@c
#ifdef NCUBE
#undef HAVE_DEBUGGER
#endif

@ To dump out all manner of cryptic stuff, set
|DBG_DUMP|.  I don't think you really want to do this.
The stuff dumped out is directly related to the last
bug I tracked down.

@c
#undef DBG_DUMP

@ To compile in some error checking on matrix
descriptors, define |CHECK_DESCR|.  I'll automatically
turn this off if |NDEBUG| is defined.

@c
#undef CHECK_DESCR
#ifdef NDEBUG
#undef CHECK_DESCR
#endif


@ I have some definitions that I'm used to.  I like to
say ``private'' instead of static when  I hide a
procedure or variable name in
 a file, and explicitly declare the rest to be ``public.''
I also like to declare
variables of type ``booln'' to hold TRUE or FALSE
values.  The |booln| typedef appears in ``matrix.h''.

@d private static
@d public
@d TRUE 1
@d FALSE 0
@f private static
@f public static
@c
@<Include files.@>

@ @<Include files.@> =

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>
#include <stdarg.h>
#include <util/group/picl.h>


@ My slightly modified version of |"assert.h"| calls the |debug| package
in case of assertion failures.
There is a timing package that is used to time
various regions of the program.
My own versions of |malloc| and  |free| can detect core leaks.
All of these things are now in libutil.h.
@<Include files.@>=
#include <util/misc/libmisc.h>

@ I think that the only reason I need this is for |fabs|.
@<Include files.@> =
#include <math.h>

@ Here is the outline of the package.

@c
@<Outer block declarations@>@/
@<Decls of the main data structures@> @/
@<Include prototypes@> @/
@<Private support functions@> @/
@<Public entry points to the package@> @/

@ The set of private support routines must be sorted to avoid
numerous forward declarations.

@<Private support...@>=
@<Miscellaneous support routines.@>@/
@<Map-related routines.@>@/
@<Matrix-related routines.@>@/

@ Let's impose some organization on the |public| routines as well.
@<Public entry...@>=
@<Public creation and destruction of matrices.@>@;@/
@<Public basic operations.@>@; @/
@<Public communications routines.@>@;@/
@<Public I/O routines.@>@; @/
@<Nestable general loop routines.@>@; @/
@<Sparse matrix routines.@>@; @/
@<Public higher level routines.@>@;@/



@ The rest of this section deals with  some necessary miscellaney:
error handling routines and the like.  The real ``meat'' of the
package begins in the next section.

Fix up some lint gripes.
@d Printf (void)printf

@ A litle |min| macro:
@<Outer block...@>=
#define min(a,b) (((a)>(b)) ? (b) : (a))

@ Get some public typedefs and macros.
@<Outer block...@>=
#include <math/dmt/matrix.h>

@ We'll need a routine to
handle errors.  
@<Miscellaneous support routines.@>=

LOCAL_FUNCTION void
fatal()
{
    Printf ("Fatal error in \"%s\"\n", rcsid);
@.Fatal error in...@>
#ifdef HAVE_DEBUGGER
    debug_start(rcsid);
#endif /*| HAVE_DEBUGGER |*/
    abort();
}

@ Some little support routines.  Copy a vector of |double|'s.
@<Miscellaneous support routines.@>=
LOCAL_FUNCTION void
dcopy (dst, src, n)
register double *dst;
register double *src;
register int n;
{
    while (n--) *dst++ = *src++;
}

@ How about a dot product.
@<Miscellaneous support routines.@>=
LOCAL_FUNCTION double
ddot (v1, v2, n)
register double *v1;
register double *v2;
register int n;
{
  register double sum = 0.0;
  while (n--) sum += (*v1++) * (*v2++);
  return (sum);
}



@ Fill a vector with copies of a scalar.
@<Miscellaneous support routines.@>=
LOCAL_FUNCTION void
dfill (v, val, n)
register double *v;
register double val;
register int n;
{
    while (n--) *v++ = val;
}


@ Scale a vector  by  a scalar.
@<Miscellaneous support routines.@>=
LOCAL_FUNCTION void
dscale (v, val, n)
register double *v;
register double val;
register int n; 
{
  while (n--) *v++ *= val;
}

@ Sum one vector into another.
@<Miscellaneous support routines.@>=
LOCAL_FUNCTION void
daccum (dst, src, n)
register double *dst;
register double *src;
register int n;
{
    while (n--) *dst++ += *src++;
}
@ Sum one scaled vector into another.
@<Miscellaneous support routines.@>=
LOCAL_FUNCTION void
dscaleaccum (dst, scale, src, n)
register double *dst;
register double scale;
register double *src;
register int n;
{
    while (n--) *dst++ += (scale * *src++);
}


@* The representation of matrices. The first thing
we'll do is to  define the data structures that hold
descriptions of the matrices. 
Each array has several attributes and tags associated
with it, and some of these can be manipulated {\it
via} public run-time routines. 

Values in the  matrices are
accessed either by columns or
by sub-matrices called {\it blocks}.  Blocks
are not necessarily of uniform size.  Rather a
user-supplied map describes the sub-division of the full
matrix into blocks. 


@<Decls of the main...@>=
  @<Decls for maps@>@/
  @<Decls for arrays@>@/
  @<Decls for ngl@>@/


@ Our description will begin with that for the
top-level description of the structure {\bf matrix} used to represent arays.
The set of defined matrices
is held in an array of these structures.
@f matrix int
@d MAX_MATRICES 50
@<Decls for arrays@> = 
struct matrixstruct {@/
    @<Members in |struct matrix|@>@;
};@/

typedef struct matrixstruct matrix;

private matrix matrices[MAX_MATRICES];

#ifdef CHECK_DESCR
matrix *check_descriptor();
#endif /*| CHECK_DESCR |*/


@ The matrix descriptors that users of this package hold
 are essentially indices into the
|matrices| array. However these descriptors could
easily encode  some extra information for
error detection.  Thus, I'll use
|ENCODE_DESCR| to
transform a |matrix| pointer into a descriptor for 
an external caller, and when
I'm called with a descriptor I'll use |DECODE_DESCR|
to recover the |matrix| pointer, 
possibly doing some error checking along the way.
Furthermore, I'll consistently declare descriptors as
|mdescr|.  The |mdescr| typedef appears in ``matrix.h'', so other
packages can access it.

@<Decls for maps@>=

#ifdef CHECK_DESCR

#define ENCODE_DESCR(ptr) ((ptr) - matrices)
#define DECODE_DESCR(descr) (check_descriptor(&matrices[(descr)]))

#else

#define ENCODE_DESCR(ptr) ((ptr) - matrices)
#define DECODE_DESCR(descr) (&matrices[(descr)])

#endif /*| CHECK_DESCR |*/


@ I'll now enumerate the various members in the |matrix| structure. 
Each matrix has a descriptive title that is supplied
to the matrix creation operations.  I imagine here a
useful title like ``2-e portion of Fock matrix''

@d MAX_TITLE 128

@<Members in |struct matrix|@>=
    char title[MAX_TITLE];

@ We'll need a public function to return the title string from a
matrix.  This returns a pointer to static storage that
gets overwritten by the next call, so look out!

@<Public basic operations.@>=

GLOBAL_FUNCTION char *
dmt_title(id) 
mdescr id;
{
    static char title_val[MAX_TITLE];
    return (strcpy (title_val, DECODE_DESCR(id) -> title));
}

@ A matrix has a size. This is |n| for an |n
@t$\times$@> n| matrix.

@<Members in |struct matrix|@>=
    int size;

@ The user can call |dmt_size| to determine the size of a
matrix.

@<Public basic operations.@>=
GLOBAL_FUNCTION int
dmt_size (id) 
mdescr id; 
{
    return ((int) DECODE_DESCR(id)->size);
}

@ The state of a matrix descriptor may be either
|STATE_OK| or  |STATE_UNDEF|.

@d STATE_OK 1
@d STATE_UNDEF 0

@<Members in |struct matrix|@>=
    char state;

@ The distribution scheme for the data in the matrix.  There are
only two choices currently:  by columns, or by scattered blocks.
In the scattered scheme, the matrix must be symmetric, and
submatrices of the matrix are scattered through the machine.  
For columns, the columns of the (non-symmetric) matrix are
distributed.  The cpp symbols |COLUMNS| and |SCATTERED| give
the possible distribution schemes and are defined in ``matrix.h''.
@<Members in |struct matrix|@>=
    char distribution;



@ We need a pointer to the map appropriate to  the matrix.  This is
just pointer to a |map| structures in an array of 
such structures.  A |map| structure
will hold a description of the blocks into which the matrix is
divided.  There are (possibly) multiple maps, since each different 
matrix size required its own map.  Furthermore, all matrices of 
a given size must share the same map.

@<Members in |struct matrix|@>=
    map *map_ptr;

@ Here is a minor point: the |matrix| structure needs a pointer to
the actual data of the matrix, on the off chance that
we may need it.

@<Members in |struct matrix|@>=
    double *data;


@ It is convenient to be able to read the distribution field of 
a matrix.  This function returns it.

@<Public basic operations.@>=
GLOBAL_FUNCTION int
dmt_distribution (m)
mdescr m;
{
  return (DECODE_DESCR (m) -> distribution);
}

@ Now that the members of |struct matrix| have been
enumerated, we'll no doubt need a routine to dump to
|stdout| everything known about a matrix structure.
The public version of this could be called from the
debugger, for instance, or by the user directly.

@<Matrix-related routines.@>=
#ifndef STRIPDOWN
LOCAL_FUNCTION void
dump_mat(m)
matrix * m;
{
/*|     begin_sequential(); |*/
    Printf ("Dump of matrix title \"%s\"\n",  m -> title);@/
@.Dump of matrix...@>
/*|     Printf ("\t state = %d\n", m -> state);@/ |*/
/*|     Printf ("\t size = %d\n", m -> size);@/ |*/
/*|     Printf ("\t distribution = %d\n", m -> distribution);@/ |*/
/*|     Printf ("\t data-pointer is %x\n", m -> data);@/ |*/
/*|     dump_map (m -> map_ptr);@/ |*/
/*|     end_sequential(); |*/
}
#endif /* STRIPDOWN */

@ Here is the public version of the dump routine.


@<Public I/O routines.@>=
#ifndef STRIPDOWN
GLOBAL_FUNCTION void
dmt_dump_mat (id) 
mdescr id;
{
    dump_mat(DECODE_DESCR (id));
}
#endif /* STRIPDOWN */


@ Not only that, but a routine to dump such data about {\it all}
matrices would be useful.


@<Public I/O routines.@>=
#ifndef STRIPDOWN
GLOBAL_FUNCTION void
dmt_dump_mats ()
{
    int i;
    for (i=0; i<MAX_MATRICES; i++)  
       if (matrices[i].state != STATE_UNDEF) dump_mat(&matrices[i]);
}
#endif /* STRIPDOWN */


@ Do some error checking to make sure that a matrix is 
OK to use.
@<Matrix-related routines.@>=

#ifdef CHECK_DESCR

private matrix *
check_descriptor(m)
matrix *m;
{
  assert (m -> title != 0);
  assert (strlen(m -> title) > 0);
  assert (m -> state == STATE_OK);
  assert (m -> distribution == COLUMNS || m -> distribution == SCATTERED);
  assert (m -> map_ptr != 0);
  assert (m -> data != 0);
  assert (m->size > 0);
  check_map (m, m -> map_ptr);
  return (m);
}

#endif /*| CHECK_DESCR |*/

@ How many matrices are currently defined?


@<Public basic operations.@>=
#ifndef STRIPDOWN
GLOBAL_FUNCTION int
dmt_num_mats ()
{
    int i, n;
    n = 0;
    for (i=0; i<MAX_MATRICES; i++)  
       if (matrices[i].state != STATE_UNDEF) n++;
    return (n);
}
#endif /* STRIPDOWN */

@ Now that the all of the outer block stuff is finished,
we can include the prototype files.
@<Include prototypes@> =
#include <tmpl.h>
#include <math/dmt/matrix.gbl>
#include <math/dmt/matrix.lcl>




@* Distribution schemes and maps.
A |map| summarizes the distribution schemes for matrices.
It details how a scattered array is divided into sub-arrays, which
columns or blocks are to be held locally, {\it etc}.
There is currently a major restriction on the subdivision of
matrices into blocks:
divisions along the rows of the matrix must be  identical to the
divisions along the columns.   That is, columns are not a special case 
of the scattered block distribution.

The structure that describes a map  has several members.  |mat_size| is
the size of the matrix to which this map applies. This is $n$ for an 
$n \times n$ matrix.  Currently, all matrices of the same size must
share the same map.  The member |nblocks| holds the number of blocks
into which each row and column of the matrix is subdivided.  In a
distributed implementation, only a subset of the blocks will be held
locally:  |n_local| is the number of locally held blocks of a
 matrix held locally
The array |blksize| gives  the size of each block:  the size of the
$i^{th}$ block is |map.blksize[i]| for |i = 0...(map.nblocks - 1)|.
For column distributions, |nlocal_cols| gives the number of columns held 
locally, and |local_cols[nlocal_cols]| holds the index of each locally held 
column.



@<Decls for maps@> = 
struct mapstruct {
    int mat_size; 		/* The size of the mapped matrix. */
    int nblocks;		/* Number of blocks in each row. */
    short int *blksize;		/* The size of each block. */
    int maxblock;              /* The largest block */
    short int *accumblksize;
    int nlocal_blocks;		/* Number of local blocks. */
    short int *local_blocks ;  /* Indices of local blocks. */
    int blk_localsize;		/* Local size required for block matrix. */
    int *block_start;          /* Starting offset for each local block. */

    int nlocal_cols;		/* Number of local columns. */
    int col_start;   		/* Starting index of local columns. */
} ;
@ The maps are held in an array of |struct map|'s.
@d MAX_MAPS 5
@f map int
@<Decls for maps@> = 
typedef struct mapstruct map;
private map maps[MAX_MAPS];


@ And a counter keeps up with the total number of defined maps.
@<Decls for maps@> = 
private int num_maps = 0;

@ This little routine returns the index of the map for matrices of
size |n|.  Returns |0| if no such map exists.

@<Map-related routines.@>=
private map * find_map(n) int n; {
    register int i;
    for (i=0;i<num_maps; i++) 
        if (maps[i].mat_size == n) return (&maps[i]);
    return (0);
}

@ Public access to the fields in the map. User may want to know, for
instance, how many columns or blocks are held locally.


@<Public basic operations.@>=
GLOBAL_FUNCTION int
dmt_nlocal(m)
mdescr m;
{
  matrix *mt = DECODE_DESCR(m);
  switch (mt -> distribution) {
  case COLUMNS: return (mt -> map_ptr -> nlocal_cols);
  case SCATTERED: return (mt -> map_ptr -> nlocal_blocks);
  default: Printf ("Bad dist field in matrix.\n"); assert (0); fatal();
  }
  return (-1);
}

@ This routine returns the largest amount of data that a chunk
of data from the matrix will require.
@<Public basic operations.@>=
GLOBAL_FUNCTION int
dmt_maxsize(m)
mdescr m;
{
  matrix *mt = DECODE_DESCR(m);
  switch (mt -> distribution) {
  case COLUMNS: return (mt -> map_ptr -> mat_size);
  case SCATTERED: return (mt->map_ptr->maxblock * mt->map_ptr->maxblock);
  default: Printf ("Bad dist field in matrix.\n"); assert (0); fatal();
  }
  return (-1);
}

@ This will return the number of blocks into which each dimension is
divided.

@<Public basic operations.@>=
GLOBAL_FUNCTION int
dmt_nblocks(m)
mdescr m;
{
  return (DECODE_DESCR(m) -> map_ptr -> nblocks);
}


@ This looks at all of the current defined maps and prints
out information about how efficient the |SCATTERED| distribution scheme is.

@<Public basic operations.@>=
GLOBAL_FUNCTION void
dmt_map_examine()
{
  int i;
  int maxsize,minsize;
  double averagesize;
  int sumsize;
  int nproc,me,host;
  who0(&nproc,&me,&host);
  if (me == 0) {
    printf("Map Examination:\n");
    printf("           %6s %6s %9s\n","min","max","mean");
    }
  for (i=0; i<num_maps; i++) {
    sumsize = maxsize = minsize = maps[i].blk_localsize;
    gmax0(&maxsize,1,2,mtype_get(),0);
    gmin0(&minsize,1,2,mtype_get(),0);
    gsum0(&sumsize,1,2,mtype_get(),0);
    if (me == 0) {
      averagesize = ((double)sumsize)/nproc;
      printf(" map %3d:  %6d %6d %9.2f\n",i,minsize,maxsize,averagesize);
      }
    }
  }

@ This is an interface to |dmt_def_map2|.  It is provided for
backward compability.
@<Public creation and destruction of matrices.@>=
GLOBAL_FUNCTION int
dmt_def_map (n, nblocks, blksize)
int n;
int nblocks;
int blksize[];
{
  return dmt_def_map2 (n, nblocks, blksize, (dmt_cost_t *) 0, 1);
  }

@ The following routine |dmt_def_map2| is the 
entry point for the definition 
of a new map.  This routine will copy the supplied data into the
structure, and compute the necessary indexing info.

The function is called with the matrix
size |n|, the number of blocks into which |n|
is subdivided |nblocks|, and a vector |blksize| giving 
the size of each block.
Is is an error  if the map
for the size |n| already exists.

The |costvec| argument is a vector of ints which is
used to classify the |nblocks*(nblocks+1)/2| blocks.  The |costvec|
provides a way for the user to impose his own ideas as to the relative
expense of a particular shell block on |dmt_def_map2|.

Whenever a map is created it is frequently useful to also have the
map for |n = nblocks| also available (that is, the map that has all
|blksize[i] == 1|.  This map was previously created with a separate
call to |dmt_def_map|, but now, because of the way that blocks are
allocated to processors in the |SCATTERED| distribution scheme, the
map for |n = nblocks| is formed automatically.  It is now an error
to try to form this map with a separate call to |dmt_def_map|.

@<Public creation and destruction of matrices.@>=
GLOBAL_FUNCTION int
dmt_def_map2 (n, nblocks, blksize, costvec, use_size)
int n;
int nblocks;
int blksize[];
dmt_cost_t costvec[];
int use_size;
{
    map *mp;
    map *mpnblock;

    @<Check |dmt_def_map| args for errors.@>;@/
    initialize_ipc_stuff();
    mp =&maps[num_maps];
    mpnblock = &maps[num_maps+1];
    mp -> mat_size = n;
    mp -> nblocks = nblocks;
    mpnblock -> mat_size = nblocks;
    mpnblock -> nblocks = nblocks;
    @<Copy |blksize| into the |mp| map.@>;@/
    @<Copy |blksize| into the |mpnblock| map.@>;@/
    @<Set column-related fields in the |mp| map.@>;@/
    @<Set column-related fields in the |mpnblock| map.@>;@/
    @<Set block-related fields in the |mp| and |mpnblock| maps.@>;@/
    num_maps += 2;
    return (0);
}

@ @<Copy |blksize| into the |mp| map.@>=
{
    register int i;
    int accum;
    mp -> blksize= (short *) Malloc (nblocks * sizeof(short));
    mp -> accumblksize= (short *) Malloc (nblocks * sizeof(short));
    mp -> maxblock = 0;
    assert (mp -> blksize != 0);
    assert (mp -> accumblksize != 0);
    accum = 0;
    for(i=0;i<nblocks;i++) {
      mp -> blksize[i] = blksize[i];
      mp -> accumblksize[i] = accum;
      accum += blksize[i];
      if (mp -> maxblock < blksize[i]) mp -> maxblock = blksize[i];
    }
    assert (accum == mp -> mat_size);
}

@ @<Copy |blksize| into the |mpnblock| map.@>=
{
    register int i;
    mpnblock -> blksize= (short *) Malloc (nblocks * sizeof(short));
    mpnblock -> accumblksize= (short *) Malloc (nblocks * sizeof(short));
    mpnblock -> maxblock = 0;
    assert (mpnblock -> blksize != 0);
    assert (mpnblock -> accumblksize != 0);
    for(i=0;i<nblocks;i++) {
      mpnblock -> blksize[i] = 1;
      mpnblock -> accumblksize[i] = i;
    }
    mpnblock -> maxblock = 1;
}


@ @<Set column-related fields in the |mp| map.@>=
{
  mp -> nlocal_cols = n / nproc; /* Number of local columns. */
  if (n % nproc > me_loop) mp -> nlocal_cols ++;
  mp -> col_start = me_loop * (n / nproc);@/
  mp -> col_start += min (n % nproc, me_loop);
}

@ @<Set column-related fields in the |mpnblock| map.@>=
{
  mpnblock -> nlocal_cols = nblocks / nproc; /* Number of local columns. */
  if (nblocks % nproc > me_loop) mpnblock -> nlocal_cols ++;
  mpnblock -> col_start = me_loop * (nblocks / nproc);@/
  mpnblock -> col_start += min (nblocks % nproc, me_loop);
}

@ For the scattered block distribution, we keep a list of all of the
index pairs |(i,j)| corresponding to the blocks held locally. This
takes up, of course, a big chunk of space---about
the space of another matrix. 

With the addition of synchronous loops, load balancing is now
quite important.  Node |0| will figure out who gets what pair of
blocks and notify the node.  When it has finished distributing all
of the data it will send everybody a block length of zero.
@<Set block-related fields...@> = 
{
  int i,j,k;
  int *size1;
  int nloc = 0;
  int blockstart = 0;
  int sblocksize,blkcost=1;
  int minbnd=0,maxbnd=0;
  int iloc=0;
  int ij,am,lvl;
  int leastbusy = 0;

  size1 = (int *) malloc(nproc*sizeof(int));
  check_alloc(size1,"dmt_map_def: size1");
  for (i=0; i<nproc; i++) size1[i] = 0;

 /* find the min and max bounds in costvec, if it is non-null */
  if (costvec) {
    ij = 0;
    for (i = 0; i < nblocks; i++) {
      for (j = 0; j <= i; j++,ij++) {
        if (costvec[ij].magnitude < minbnd) minbnd=costvec[ij].magnitude;
        if (costvec[ij].magnitude > maxbnd) maxbnd=costvec[ij].magnitude;
        }
      }
    }

 /* I'm still playing around with what BLKCOST should be */
#define BLKCOST(i,j,ij) \
  { int maxam = (costvec[ij].ami>costvec[ij].amj) ? \
                                 costvec[ij].ami : costvec[ij].amj; \
    blkcost = sblocksize;\
  }

 /* determine how many blocks each node will hold */
  if (use_size) {
    for (i=ij=0; i<nblocks; i++) {
      for (j=0; j<=i; j++,ij++) {
        sblocksize = mp -> blksize[i] * mp -> blksize[j];
        if (use_size) blkcost=sblocksize;
        /* Find the processor with the least amount of work allocated. */
        for (k=0; k<nproc; k++) {
          if (size1[leastbusy] > size1[k]) leastbusy = k;
          }
        size1[leastbusy] += blkcost;
        if(leastbusy==me) nloc++;
        }
      }
    }
  else {
    for (am=10; am > -1; am--) {
      for (lvl=maxbnd; lvl >= minbnd; lvl--) {
        for (i=ij=0; i < nblocks; i++) {
          for (j=0; j <= i; j++,ij++) {
            if ((costvec[ij].ami + costvec[ij].amj) != am) continue;
            if (costvec[ij].magnitude!=lvl) continue;

            sblocksize = mp->blksize[i] * mp->blksize[j];

            if (use_size)
              blkcost = sblocksize;
            else
              BLKCOST(i,j,ij);

            for (k = 0; k < nproc; k++) {
              if (size1[leastbusy] > size1[k])
                leastbusy = k;
              }
            size1[leastbusy] += blkcost;
            if (leastbusy == me)
              nloc++;
            }
          }
        }
      }
    }

  /* Allocate storage for the local blocks. */
  mp -> local_blocks = (short *) Malloc (2 * nloc * sizeof (short));
  mp -> block_start = (int *) Malloc (nloc * sizeof (int));
  check_alloc (mp->local_blocks , "mp->local_blocks ");
  check_alloc (mp->block_start , "mp->block_start ");
  mpnblock -> local_blocks = (short *) Malloc (2 * nloc * sizeof (short));
  mpnblock -> block_start = (int *) Malloc (nloc * sizeof (int));
  check_alloc (mpnblock->local_blocks , "mpnblock->local_blocks ");
  check_alloc (mpnblock->block_start , "mpnblock->block_start ");

  /* now pass out the blocks to the nodes */
  leastbusy=0;
  for (i=0; i<nproc; i++) size1[i] = 0;

  if (use_size) {
    for (i=ij=0; i<nblocks; i++) {
      for (j=0; j<=i; j++,ij++) {
        sblocksize = mp -> blksize[i] * mp -> blksize[j];
        if(use_size) blkcost=sblocksize;

        /* Find the processor with the least amount of work allocated. */
        for (k=0; k<nproc; k++) {
          if (size1[leastbusy] > size1[k]) leastbusy = k;
          }
        size1[leastbusy] += blkcost;
        if(leastbusy==me) {
          mp -> local_blocks[2*iloc] = i;
          mp -> local_blocks[2*iloc+1] = j;
          mp -> block_start[iloc] = blockstart;
          mpnblock -> local_blocks[2*iloc] = i;
          mpnblock -> local_blocks[2*iloc+1] = j;
          mpnblock -> block_start[iloc] = iloc;
          blockstart += sblocksize;
          iloc++;
          }
        }
      }
    }
  else {
    for (am=10; am > -1; am--) {
      for (lvl=maxbnd; lvl >= minbnd; lvl--) {
        for (i=ij=0; i < nblocks; i++) {
          for (j = 0; j <= i; j++,ij++) {
            if ((costvec[ij].ami + costvec[ij].amj) != am) continue;
            if (costvec[ij].magnitude!=lvl) continue;

            sblocksize = mp->blksize[i] * mp->blksize[j];

            if (use_size)
              blkcost = sblocksize;
            else
              BLKCOST(i,j,ij);

            for (k = 0; k < nproc; k++) {
              if (size1[leastbusy] > size1[k])
                leastbusy = k;
              }
            size1[leastbusy] += blkcost;
            if (leastbusy == me) {
              mp->local_blocks[2 * iloc] = i;
              mp->local_blocks[2 * iloc + 1] = j;
              mp->block_start[iloc] = blockstart;
              mpnblock->local_blocks[2 * iloc] = i;
              mpnblock->local_blocks[2 * iloc + 1] = j;
              mpnblock->block_start[iloc] = iloc;
              blockstart += sblocksize;
              iloc++;
              }
            }
          }
        }
      }
    }

  mp -> blk_localsize = blockstart;
  mp -> nlocal_blocks = nloc;
  mpnblock -> blk_localsize = nloc;
  mpnblock -> nlocal_blocks = nloc;
  free(size1);
}




@ @<Check |dmt_def_map| args for errors.@>=
{
    int i, nsum;
    assert(num_maps + 1< MAX_MAPS);
    assert (find_map (n) == 0);
    assert (find_map (nblocks) == 0);
    nsum = 0;
    for (i=0;i<nblocks; i++) nsum += blksize[i];
    assert (nsum == n);
}



@ This routine does what it can to verify that a map
seems OK, and that it is consistent with the matrix that
points to it.

@<Private support...@>=
#ifdef CHECK_DESCR
private void
check_map(mt, mp)
matrix *mt;
map *mp;
{
  int i;
  assert (mp -> mat_size > 0);
  assert (mp -> mat_size == mt -> size);
  assert (mp -> nblocks > 0);
  for (i=0; i<mp->nblocks; i++) assert (mp->blksize[i] > 0);
  for (i=0; i<mp->nblocks; i++) assert (mp->blksize[i] <= mp->maxblock);
  for (i=0; i<mp->nblocks; i++) {
    if (i > 0) assert (mp -> accumblksize[i]);
    if (i < 0) assert (mp -> accumblksize[i] ==
		       mp -> accumblksize[i-1] + mp -> blksize[i-1]);
  }
  if (mp -> mat_size >= nproc) {
    assert (mp -> nlocal_blocks > 0);
    assert (mp -> blk_localsize > 0);
  }
/*|   for (i = 1; i < mp->nlocal_blocks; i++)  |*/
  if (mp->nlocal_blocks > 1) {
    i = 1;
    assert (mp->block_start[i] > 0);
    assert (mp->block_start[i] > mp->block_start[i-1]);
    assert (mp->block_start[i] < mp->blk_localsize);
    i = mp->nlocal_blocks-1;
    assert (mp->block_start[i] > 0);
    assert (mp->block_start[i] > mp->block_start[i-1]);
    assert (mp->block_start[i] < mp->blk_localsize);
  }
  if (mp -> mat_size >= nproc) {
    assert (mp -> nlocal_cols > 0);
    assert (mp -> col_start > -1);
  }
  assert ( mp -> col_start <= mp -> mat_size);
}

#endif /*| CHECK_DESCR |*/

@ This private routine returns the local size (in |double|'s) required for 
a  matrix.
@<Private support...@>=
LOCAL_FUNCTION int
localsize(m)
matrix *m;
{
    map * mp = m -> map_ptr;
    switch (m -> distribution){
    case COLUMNS: return (mp -> nlocal_cols * mp -> mat_size);
    case SCATTERED: return (mp -> blk_localsize);
    default: Printf ("Bogus distribution field\n"); assert (0); fatal();
    }
    return (-1);
}


@ Given a block index, we can return a description of the 
corresponding matrix elements.  This takes as input, the matrix
descriptor |md| and the block index |b|.  It returns the starting
element number for the block |start| and the size of the
block |size|.  


@<Public basic operations.@>=
GLOBAL_FUNCTION void
dmt_describe_block (md, b, start, size)
mdescr md;
int b;
int *start;
int *size;
{
  matrix *m=DECODE_DESCR(md);
  map *mp = m -> map_ptr;
  *start = mp->accumblksize[b];
  *size = mp -> blksize[b];
}


@ After creating a map, 
we'll of course need to dump it back out.  Give this routine the 
pointer to a  map, and it will dump the map's contents to |stdout|.

@<Map-related routines.@>=
#ifndef STRIPDOWN
LOCAL_FUNCTION void
dump_map(mp)
map *mp;
{
    int nblocks;
    Printf ("\t\t Dump of a map.\n");
    Printf ("\t\t matrix size is %d\n", mp -> mat_size);
    Printf ("\t\t number of blocks is %d\n", mp -> nblocks);@/
    nblocks = mp -> nblocks;
    @<Print the block and accumblock maps.@>;
    Printf ("\t\t %d local columns starting at %d.\n", mp -> nlocal_cols,
	mp -> col_start);
    Printf ("\t\t local size for scattered mat = %d\n", mp -> blk_localsize);
    Printf ("\t\t local blocks = %d\n", mp -> nlocal_blocks);
    @<Print the scattered block map.@>@;
}
#endif /*STRIPDOWN*/

@ @<Print the block and accumblock maps.@>=
{
  int i;
  Printf ("\t\t The block (accum) map:\n\t\t");@/
  for (i=0; i<nblocks; i++) {
    Printf (" %d (%d)", mp -> blksize[i], mp -> accumblksize[i]);
    if (!((i+1) % 15)) Printf ("\n\t\t");
  }
  Printf ("\n");
}

@ @<Print the scattered block map.@>=
{
    int i;
    Printf ("\t\t The scattered block map:\n\t\t");@/
    for (i=0; i<mp->nlocal_blocks; i++) {
        Printf ("(%d,%d) ", mp -> local_blocks[2*i], mp -> local_blocks[2*i+1]);
	if (!((i+1) % 10)) Printf ("\n\t\t");
    }
    Printf ("\n");
}

@ Here is a public version of this dump-map routine, called with the
matrix size whose map is to be dumped.


@<Public  I/O routines.@>=
#ifndef STRIPDOWN
GLOBAL_FUNCTION void
dmt_dump_map(n) 
int n;
{
  map *m;
  if ((m=find_map(n)) != 0) dump_map(m);
  else {
    Printf ("No map for size %d to dump.\n", n);
@.No map for size...@>
      assert(0);
    fatal();
  }
}
#endif /*STRIPDOWN*/




@* Access to local blocks and columns.  This is
provided by two routines---one for access to blocks,
and one for access to columns.  These take a matrix
descriptor and a local index as inputs.  For columns,
you get back the global column index, and a pointer to
the start of the column.  You can then modify the data
if you want.


@<Public basic operations.@>=
GLOBAL_FUNCTION void
dmt_get_col(md, lind, gind, data)
mdescr md;
int lind;
int *gind;
double **data;
{
  matrix *m=DECODE_DESCR(md);
  map * mp = m -> map_ptr;
  assert (lind < mp -> nlocal_cols);
  assert (m -> distribution == COLUMNS);
  *gind = mp -> col_start + lind;
  *data = m -> data + mp -> mat_size * lind;
}


@ For access to blocks, we require the same two inputs---a 
matrix descriptor |md|
 and a local index |lind|.
  The outputs are
the two indices for the block |(i,j)|, and a pointer to the start of the
block |data|.

@<Public basic operations.@>=
GLOBAL_FUNCTION void
dmt_get_block(md, lind, i, j, data)
mdescr md;
int lind;
int *i;
int *j;
double **data;
{
  matrix *m=DECODE_DESCR(md);
  map * mp = m -> map_ptr;
  assert (lind < mp -> nlocal_blocks);
  assert (m -> distribution == SCATTERED);
  *i = mp -> local_blocks[2*lind];
  *j = mp -> local_blocks[2*lind+1];
  *data = m -> data + mp -> block_start[lind];
}
@ This one also returns the block sizes.

@<Public basic operations.@>=
GLOBAL_FUNCTION void
dmt_get_block_dsc(md, lind, i, isiz, j, jsiz, data)
mdescr md;
int lind;
int *i;
int *isiz;
int *j;
int *jsiz;
double **data;
{
  matrix *m=DECODE_DESCR(md);
  map * mp = m -> map_ptr;
  assert (lind < mp -> nlocal_blocks);
  assert (m -> distribution == SCATTERED);
  *i = mp -> local_blocks[2*lind];
  *j = mp -> local_blocks[2*lind+1];
  *isiz = mp -> blksize[*i];
  *jsiz = mp -> blksize[*j];
  *data = m -> data + mp -> block_start[lind];
}








@* Creating and destroying matrices..  This section
starts to flesh out the handling of matrices, building
upon structures and routines described previously.
We'll deal with creating, opening, closing, and
deleting matrices, first of all.

Return the index of a matrix, given its title.  Return $0$ if no such
matrix exists.

@<Matrix-related routines.@>=
LOCAL_FUNCTION matrix *
loc_mat (title)
char *title; 
{
    int j;
    for(j=0; j<MAX_MATRICES; j++)
    	if (matrices[j].state != STATE_UNDEF && 
	    (!strcmp(title, matrices[j].title))) return (&matrices[j]);
    return (0);
}

@ Here is the public version of this operation.  This routine,
|dmt_old|, requires that the matrix exists.  If it doesn't, then
a fatal error results.


@<Public basic operations.@>=
#ifndef STRIPDOWN
GLOBAL_FUNCTION mdescr
dmt_old (title)
char *title;
{
  matrix *m;
  m = loc_mat (title);
  if (m != 0) return (ENCODE_DESCR(m));
  assert (0);
  fatal (); return (-1);
}
#endif /*STRIPDOWN*/

@ Free up a matrix.  we simply de-allocate the space holding the data,
and mark the matrix |STATE_UNDEF|


@<Public creation and destr...@>=
GLOBAL_FUNCTION void
dmt_free(d)
mdescr d;
{
  matrix *m = DECODE_DESCR(d);
  if (m -> state == STATE_OK) {
    Free (m -> data);
    m -> state = STATE_UNDEF;
  }
  else {
    assert (0);
    fatal();
  }
}

@ Create a nil matrix (an invalid matrix desciptor).
@<Public creation and destr...@>=
GLOBAL_FUNCTION mdescr
dmt_nil()
{
  return -1;
  }


@ This public routine creates a new matrix.  It is called with the
title of the matrix, its size, and a specification indicating
the required distribution of the matrix.
  It is an error if the named matrix already exists.



@<Public creation and destr...@>=
GLOBAL_FUNCTION mdescr
dmt_create (title, size, distrib)
char *title;
int size;
int distrib;
{
    matrix *nmat;
    int needspace, i;
    @<Point |i| to an empty slot.@>;@/
    nmat = &matrices[i];@/
    @<Copy the title into |nmat|.@>;@/
    nmat -> state = STATE_OK;
    nmat -> size = size;
    nmat -> distribution = distrib;
    if ((nmat -> map_ptr = find_map (size)) == 0){fatal();}
    needspace = localsize(nmat);
    nmat -> data = (double *) Malloc (sizeof(double) * needspace);
    if (nmat -> data == (double *) 0) {
      void dmt_dump_mats();
      printf ("Failed to allocate space for %s, needed %d\n",title,needspace);
      dmt_dump_mats();
      assert (0);
      fatal();
    }
    dfill(nmat -> data,  0.0, needspace);
    return (ENCODE_DESCR(&matrices[i]));
}


@ @<Point |i| to an empty slot.@> =
{
    for (i=0; i<MAX_MATRICES; i++) {
        if (matrices[i].state == STATE_UNDEF) break;
    }
    if (matrices[i].state != STATE_UNDEF) {
        Printf ("Ran out of matrices creating \"%s\"\n", title);
@.Ran out of matrices...@>
        assert (0);
	fatal();
    }
}

@ @<Copy the title into |nmat|.@> =
{
    if (strlen(title) == 0){Printf("Create: null title.\n"); assert (0); fatal();}
@.Create: null title.@>
    if ((int) strlen(title) + 1 > MAX_TITLE) {
        Printf ("Title too long: \"%s\"\n", title); assert (0);fatal ();
@.Title too long@>
    }
    {
      strcpy (nmat -> title, title);
    }
}



@* Loop communication.  Interprocessor communication in
this package is built around a {\it loop} of processors.
The first thing you must do to communicate is to put a
copy of a matrix ``on the loop.''  After this, you can
repeatedly ``get'' the next column or block from the
loop, possibly modify it, and optionally send that
column or block along to the next processor in the
loop.  The initialization is such that after you ``put'' a
matrix on the loop, the first blocks or columns you
then ``get'' are your own.
Although the blocks in a scattered block array
may be small, this interface can arrange to buffer them
into large chunks for efficient message traffic.  Note
that any column or block ``sent'' to a neighbor must
eventually be removed from the loop by ``getting'' it
without a subsequent ``send'' operation.  A reasonable
way to ensure this is to have the processor that 
puts the block or column onto the loop be
responsible for its eventual removal.

In this section, we'll provide a |private| loop
transport interface.  Then, in the next, we'll provide
the |public| routines that use this to transfer columns
and scatered blocks around the loop.

@ We'll need to declare some loop-related stuff in the outer block
@<Outer block...@>=
@<Loop declarations in the outer block.@>

@ This contains the value set by |dmt_set_throttle|, the value set
by |dmt_set_sync_loop|, and a
list of outbound neighbors that seed data will be sent to.
The |n_sync| variable keeps track of the number of synchronization
messages that we expect to receive.
@<Loop declarations in the outer block.@>=
private int throttle = 0;
private int sync_loop = 0;
private int n_sync;
private int *out_neigh_list = NULL;
private int most_distant_out_neigh = -1;
private int most_distant_in_neigh = -1;


@* The public communications routines.
Here are the user-callable routines for loop manipulation.  

The the value of |sync_loop| for loop communications.  A value
of |-1| turns off all synchronization.  Values equal to or greater than zero
gives the number of synchronization messages that can be missing
from the out neighbor for it to be sent a new block.
@<Public communications routines.@>=
GLOBAL_FUNCTION VOID
dmt_set_sync_loop(sl)
int sl;
{
  sync_loop = sl;
  }

@ Set the throttle for loop communication.  The argument is the
number of nodes ahead the data is sent before processing of
the current data begins.  A value of |0| turns throttling off.
@<Public communications routines.@>=
GLOBAL_FUNCTION VOID
dmt_set_throttle(val)
int val;
{

  if (val > nproc) throttle = nproc;
  else throttle = val;

  if (throttle > 0) {
    int i;
    if (out_neigh_list) {
      free(out_neigh_list);
      }
    out_neigh_list = (int *)malloc(sizeof(int)*throttle);
    check_alloc(out_neigh_list,"out_neigh_list");
    for (i=0; i<throttle; i++) {
      out_neigh_list[i] = loop_neigh(i+1);
      }
    most_distant_out_neigh = loop_neigh(throttle+1);
    most_distant_in_neigh = loop_neigh(-(throttle+1));
    }
  else {
    if (out_neigh_list) {
      free(out_neigh_list);
      out_neigh_list = NULL;
      }
    most_distant_out_neigh = loop_neigh(1);
    most_distant_in_neigh = loop_neigh(-1);
    }

  }

@* Converting between distribution schemes.  There are
two routines that convert between |SCATTERED| and
|COLUMNS| matrix distributions.  These routines make a
copy of their argument matrix in the requested new
distribution. These routines used the loop system, to
the loop must be currently empty.

First, convert from columns to scattered.  Arguments
are the title for the new matrix, and a column-matrix
to copy into scattered form.  The input matrix must be
symmetric (since that is a requirement of all scattered
matrices) and be currently in |COLUMNS| distribution.
Since the matrix is symmetric, we'll pretend that we
have rows instead of columns.


@<Public basic operations.@>=
GLOBAL_FUNCTION mdescr
dmt_scatter(title, in_mat)
char *title;
mdescr in_mat;
{
  int n = dmt_size(in_mat);
  mdescr newmat = dmt_create(title, n, SCATTERED);
  assert (dmt_distribution(in_mat) == COLUMNS);
  cols_to_scatt(in_mat, newmat);
  return (newmat);
}

@ This routine actually accomplishes the column to scatter
transformation.
@<Private support...@>=
LOCAL_FUNCTION void
cols_to_scatt (in_mat, newmat)
mdescr in_mat;
mdescr newmat;
{
  int newlocal = dmt_nlocal (newmat);
  int irow;
  double *row;
  loop_t* loop;
  int ijunk,isz,junksz;
  loop = dmt_ngl_create("%mr",in_mat);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&ijunk,&isz,&irow,&junksz,&row)) {
      @<Copy row |irow| into local blocks of |newmat|.@>;
      }
    }
  dmt_ngl_kill(loop);
}

@ We just examine each locally held block of |newmat| to see
if the row contributes.

@<Copy row |irow| into local blocks of |newmat|.@>=
{
  int ind, jnd;
  int lind;
  int istart, ilen, jstart, jlen;
  double *block;
  for (lind = 0; lind < newlocal; lind++) {
    dmt_get_block(newmat, lind, &ind, &jnd, &block);
    dmt_describe_block (newmat, ind, &istart, &ilen);
    dmt_describe_block (newmat, jnd, &jstart, &jlen);
    if (irow >= istart && irow < (istart + ilen)) {
      int j;
      double *blkptr = block + (irow - istart) * jlen;
      double *rowptr = row + jstart;
      for (j = 0; j < jlen; j++) *blkptr++ = *rowptr++;
    }
  }
}

@ This next routine converts from scattered blocks to columns.  The
resulting column-distributed matrix will, of course, be symmetric.


@<Public basic operations.@>=
GLOBAL_FUNCTION mdescr
dmt_columns(title, in_mat)
char *title;
mdescr in_mat;
{
  mdescr newmat = dmt_create(title, dmt_size(in_mat), COLUMNS);
  assert (dmt_distribution (in_mat) == SCATTERED);
  scatt_to_cols (in_mat, newmat);
  return (newmat);
}
@ This routine |scatt_to_cols| actually accomplishes the scatter to
column transformation.

@<Private support...@>=
LOCAL_FUNCTION void
scatt_to_cols (in_mat, newmat)
mdescr in_mat;
mdescr newmat;
{
  int local_rows = dmt_nlocal (newmat);
  int iblk, jblk;
  double *block;

  loop_t* loop;
  int isz,jsz;
  loop = dmt_ngl_create("%mr",in_mat);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&iblk,&isz,&jblk,&jsz,&block)) {
      @<Copy block |(iblk, jblk)| into locally held rows.@>;
      }
    }
  dmt_ngl_kill(loop);
}

@ We just examine each locally held row and copy from the
block as appropriate. This got bigger that I expected.  I should
re-do this to make it comprehensible $\ldots$

@<Copy block |(iblk, jblk)| into locally held rows.@>=
{
  int lrind;    /* Local row index. */
  int grind;    /* Global index for the local row. */
  double *row;  /* The row. */
  int ibstart, iblen, jbstart, jblen;

  dmt_describe_block (in_mat, iblk, &ibstart, &iblen);
  dmt_describe_block (in_mat, jblk, &jbstart, &jblen);

  for (lrind = 0; lrind < local_rows; lrind ++) {
    dmt_get_col (newmat, lrind, &grind, &row);
    if ((grind >= ibstart) && (grind < (ibstart + iblen))){
      int j;
      double *blkptr = block + (jblen * (grind - ibstart));
      double *rowptr = row + jbstart;
      for (j = 0; j < jblen; j++) {
	*rowptr++ = *blkptr++;
      }
    }
    if ((grind >= jbstart) && (grind < (jbstart + jblen))){
      int i;
      double *blkptr = block + (grind - jbstart);
      double *rowptr = row + ibstart;
      for (i = 0; i < iblen; i++) {
	*rowptr++ = *blkptr;
	blkptr += jblen;
      }
    }
  }
}

@* Identifications of other processors.
 We'll need to keep up with the  number of processors and
the index of the current process.  |nproc| holds the total number
of processors availble.
@<Outer block...@> = 
private int nproc = -1;
private int me;   		/* My node id. */
private int me_loop;      /* My index in the loop. */ 
private int out_neigh;    /* The neighbor to whom I send loop msgs. */
private int in_neigh;    /* The neighbor from which I receive msgs. */
private int iochan;

@ This little routine handles the initialization of the various indices.
@<Private support...@>=
LOCAL_FUNCTION void
initialize_ipc_stuff()
{
  me = mynode0();
  nproc = numnodes0();
  me_loop = my_loop_index();
  out_neigh = loop_out_neigh();
  in_neigh = loop_in_neigh();
  iochan = 0;
}

@ The message types used by \.{libdmt} (the nestable general loop routines
use their own, computed, types):
@d MTYPE_BASE     401
@d MTYPE_NLOCAL   MTYPE_BASE+5
@d MTYPE_LOOPSYNC MTYPE_BASE+6
@d MTYPE_LOOP     MTYPE_BASE+11
@d MTYPE_MAP      MTYPE_BASE+1000
@d MTYPE_NGL      MTYPE_BASE+2000

@ Especially for debugging, we sometimes need to have
every processor do something, only do it one at a time.
These two routines arrange for that to happen.  Call
the first of these |begin_sequential|, just before such
a section.  Call |end_sequential| at the end.
@<Private support...@>=

private int seq_depth = 0;
private int seq_type;

LOCAL_FUNCTION void
begin_sequential () 
{
  int val;
  seq_type = mtype_get();
  seq_depth++;
  assert (seq_depth == 1);
  if (mynode0() == 0) return;
  recv0 ((char *) &val, 1, seq_type);
#ifdef HAVE_INFOCOUNT
  assert (infocount() == 1);
#endif
}


LOCAL_FUNCTION void
end_sequential ()
{
  int val;
  assert (seq_depth == 1);
  seq_depth--;
  send0 ((char *) &val, 1, seq_type, out_neigh);
  if (mynode0 () == 0) {
    recv0 ((char *) &val, 1, seq_type);
#ifdef HAVE_INFOCOUNT
    assert (infocount() == 1);
#endif
  }
}


@ This little routine is a special case for the |gop0| routine.
@<Private support...@>=
LOCAL_FUNCTION double
lcl_gop(val, op, type)
double val;
int op;
int type;
{
  gop0 (&val, 1, op, type);
  return (val);
}

@* I/O for matrices.  This section provides a set of
routines for reading and writing matrices to and from
files.  The names of these routines, and the sequence
of the calling arguments are taken---generally---from
the associated Unix routines.  Thus, |dmt_printf|
requires a format string and the matrix descriptor, and
prints the matrix to the standard output.  There is
also |dmt_fprintf|, which takes a file name, format
string, and matrix.  A generalization of this system
provides |dmt_print| and |dmt_fprint| which use a
default format string.  |dmt_write| writes a binary
form of matrix into a named file.

@ Print out a matrix with default |double| output format.

@<Public I/O routines.@>=

GLOBAL_FUNCTION void
dmt_print (m)
mdescr m;
{
    dmt_printf ("%13.6e ", m);
}

@ Here is the matrix print routine.  It's not very
pretty, and makes assumptions about the distribution of
the columns. We can really only print out a matrix in
column distribution form---if the supplied matrix is
not in this form, then we transform it to this form
before printing.


@<Public I/O routines.@>=

GLOBAL_FUNCTION void
dmt_printf (fmt, m)
char *fmt;
mdescr m;
{
  mdescr pmat = (DECODE_DESCR(m) -> distribution == COLUMNS) ?
    m : dmt_columns ("dmt_print",m);
  int nl = dmt_nlocal (pmat);
  int n = dmt_size(pmat);
  int gind, i, j, ncount;
  double *col;
  if (me == 0) printf("\"%s \" matrix \n", dmt_title(m));
  begin_sequential();
  for (i = 0; i < nl; i++){
    dmt_get_col (pmat, i, &gind, &col);
    printf ("(%d)  ", gind); ncount = 0;
    for (j = 0; j < n; j ++) {
      printf (fmt, col[j]);
      if (ncount++ > 5 && j != (n-1)) {ncount = 0; printf ("\n   ");}
    }
    printf ("\n");
  }
  end_sequential();
  if (pmat != m) dmt_free (pmat);
}

@ Write out a matrix to a file.  I'll do this
differently from |dmt_print|---this routine will use
the loop to pass columns around.  Like the printing
routine, this really really only handles the |COLUMNS|
distribution scheme.  If we are given a |SCATTERED|
matrix, we'll convert it to columns first.

The public entry points simply call the |private| routine
|write_matrix|, which does all the work.


@<Public I/O routines.@>=

GLOBAL_FUNCTION VOID dmt_write (fname, mat)
char *fname;			/* Target file name. */
mdescr mat;			/* The matrix to write. */
{
  write_matrix (fname, mat, 1);
}

@

@<Public I/O routines.@>=

GLOBAL_FUNCTION void
dmt_fprint (fname, mat)
char *fname;			/* Target file name. */
mdescr mat;			/* The matrix to write. */
{
  write_matrix (fname, mat, 0);
}

@ Here  is the |private| routine that writes either binary
or text versions of the file.  I'll try not to make
assumptions about the distribution scheme for the
|COLUMNS|.  Thus, we'll put the matrix onto the loop,
and node zero will write out tne columns in whatever
sequence they appear on the loop.  For the text version
of the file, I'll prepend the columns number to the
line, as with |dmt_print|.  For the binary version,
I'll |lseek| to the proper location in the file so that
the columns appear in ascending order.
If |binp| is false, and the filename is null, then the matrix
is printed to |stdout|.


@<Private support...@>=
void write_matrix (fname, m, binp)
char *fname; 			/* The name of the file to be written. */
mdescr m;   			/* The matrix to write. */
booln binp; 			/* Binary? 0/1 $\rightarrow$ text/binary. */
{
  void dmt_free();
  int ncols = dmt_size(m);		/* Size of the matrix. */
  mdescr wmat;				/* A column version of |m| */
  FILE *f;				/* Text file. */
  int fd;				/* Binary file. */
  int ind; double *col;
  loop_t* loop;
  int iind,isize,jsize;

  @<Open the file and make |wmat|.@>;
  loop = dmt_ngl_create("%mr",wmat);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&iind,&isize,&ind,&jsize,&col)) {
      if (mynode0() == 0) @<Write out column |ind|.@>;
      }
    }
  dmt_ngl_kill(loop);
  @<Free |wmat| and close the file.@>;
}

@ In opening the file, we use either |open| or
|fopen|, depending upon the value of |binp|.  

@<Open the file and make |wmat|.@>=
{
  if (mynode0() == 0){
    if (binp) {
      fd = open (fname, O_CREAT | O_WRONLY | O_TRUNC, 0664);
      if (fd == -1) perror ("dmt_write");
      assert (fd != -1);
    } else {
      if (strlen(fname)) f = fopen (fname, "w");
      else f = stdout;
      if (f == 0) perror ("dmt_write");
      assert (f != 0);
    }
  }
  /* Make |pmat| be a column version of |m|. */
  if (DECODE_DESCR(m) -> distribution == COLUMNS) 
    wmat =  m;
  else
    wmat = dmt_columns ("write_matrix",m);
}

@ Get definitions of |O_CREAT|, {\it etc.}

@<Include files.@> =
#ifdef NCUBE
#include <fcntl.h>
#else /* NCUBE */
#ifdef RS6000
#include <fcntl.h>
#define O_RDONLY 00000000
#define O_WRONLY 00000001
#define O_CREAT 00000400
#define O_TRUNC 00001000
#else /* RS6000 */
#include <sys/fcntl.h>
#endif /* RS6000 */
#endif /* NCUBE */

@ In writing out the column, we first examine |binp| to determine
whether we do a |lseek| and a |write|, or a |fprintf| to write out
the column.

@<Write out column |ind|.@>=
{
  if (binp) {  			/* Binary file. */
    off_t offset = (off_t)  (ncols * ind * sizeof(double));
#ifdef UNICOS
    off_t seekval = lseek (fd, offset , SEEK_SET);
#else
    off_t seekval = lseek (fd, offset , L_SET);
#endif
    int writeval;
    assert (offset == seekval);
#ifdef NCUBE
    r8n (col, ncols);   /* Byte swapping stuff. */
#endif
    writeval = write (fd, (void*)col, ncols * sizeof(double));
    assert (writeval == ncols * sizeof (double));
#ifdef NCUBE
    r8n (col, ncols);   /* Byte swapping stuff. */
#endif
  } else {			/* Text file. */
    int j;
    fprintf (f, "(%d)", ind);
    for (j = 0; j < ncols; j++) fprintf (f, " %.13e ", col[j]);
    fprintf (f, "\n");
  }
}

@ These are  for |lseek|.  Folks can't seem to make up their minds
about where these belong

@<Include files.@> =

#if defined(NCUBE)
#define off_t long
#else
#include <sys/types.h>
#endif

#undef GOTONE

#ifdef I860
#include <unistd.h>
#define GOTONE
#endif

#ifdef NCUBE
#include <unistd.h>
#define GOTONE
#endif

#ifdef UNICOS
#include <sys/unistd.h>
#define GOTONE
#endif

#ifdef linux
#include <unistd.h>
#endif

#ifndef GOTONE
#include <sys/file.h>
#endif

#ifndef L_SET
#define L_SET SEEK_SET
#endif

@ We must remove the next incoming |nlocal| columns
from the loop before killing it.  Also, if |wmat| was
created by this routine, then we must deallocate it.

@<Free |wmat| and close the file.@>=
{
  if (wmat != m) dmt_free (wmat);
  if (mynode0() == 0){
    if (binp) close (fd);
    else
      if (f != stdout) fclose(f);
  }
}



@ Read in a binary matrix from a file.  |dmt_read|
takes a filename and a matrix descriptor as arguments,
and reads the matrix from the file.  This is implemented by
putting the matrix on the loop.  Node zero then examines
each column as it goes by, uses |lseek| to position 
to the right place in the file, and reads in the 
column data.  

@<Public I/O routines.@>=
GLOBAL_FUNCTION void
dmt_read(fname, m)
char *fname;
mdescr m;
{
  int fd;
  int nbasis = dmt_size(m);
  mdescr rmat= (dmt_distribution (m) == COLUMNS) ? m :
    dmt_create ("dmt_read temp mat", nbasis, COLUMNS);
  loop_t* loop;
  int junkind,junksize,junk2size;
  int ind; double *col;
  
  @<Open |fname| for read access.@>;


  loop = dmt_ngl_create("%m",rmat);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&junkind,&junksize,&ind,&junk2size,&col)) {
      @<Node zero reads the column.@>;
      }
    }
  dmt_ngl_kill(loop);
  if (mynode0() == 0) close (fd);
  @<Reshape |rmat| into scattered |m| if necessary.@>;
}

@ If we are node zero, then we must |lseek| to the
right place in the file, and read in the column.

@<Node zero reads the column.@>=
if (mynode0() == 0) {
  off_t offset = (off_t)  (nbasis * ind * sizeof(double));
#ifdef UNICOS
  off_t seekval = lseek (fd, offset , SEEK_SET);
#else
  off_t seekval = lseek (fd, offset , L_SET);
#endif
  int readval;
  int nleft,read_offset,max_words=64; /* The ncube can only read 512 bytes */
  assert (offset == seekval);
  if (nbasis > max_words)
    {
      nleft = nbasis;
      read_offset= 0;
      readval=0;
      while(nleft > max_words)
	{
	  readval+= read(fd,(void*)(col+read_offset),max_words*sizeof(double));
	  nleft-=max_words;
	  read_offset+=max_words;
	}
      readval+= read(fd,(void*)(col+read_offset),nleft*sizeof(double));
    }
  else
    {
      readval= read(fd,(void*)col,nbasis*sizeof(double));
    }

  assert (readval == nbasis * sizeof (double));
#ifdef NCUBE
  r8n (col, nbasis);   /* Byte swapping stuff. */
#endif
}


@ |open| the file |fname| for read access.  Print an error
message and exit if it fails.
@<Open |fname| for read access.@>=

  if (mynode0() == 0) {
    fd = open(fname, O_RDONLY);
    if (fd == -1) {
      fprintf (stderr, "Couldn't open %s to read \"%s\"\n",
	       fname, dmt_title (m)); exit(1);
    }
  }

@  @<Reshape |rmat| into scattered |m| if necessary.@>=
{
  if (m != rmat) {
    dmt_copy (rmat, m);
    dmt_free (rmat);
  }
}


@* Higher level matrix operations.  Here, we finally
are ready to write stuff like matrix multiply.  I think
we've devloped all of the support we need.


@ Convert a distributed matrix to a locally held one.  Each
node end up with a copy of the matrix when this routine
exits.  The matrix descriptor is |md| and |data| is a vector of pointers
to double, which is where the matrix is copied to.  If the matrix
does not use the columns distribution scheme, it is first converted
to a columns matrix.  The |data| array must be symmetric in
this version of the routine and is set up in such a way that data[0] has
length 1, data[2] has length 2, and so on.  If |md| is a |SCATTERED|
matrix, it is first converted to a |COLUMNS| distribution scheme.

@<Public higher level routines.@>=
GLOBAL_FUNCTION void
dmt_mdescr_to_local_s(md,data)
mdescr md;
double**data;
{
  int j;
  matrix *m = DECODE_DESCR(md);
  mdescr mdtmp;
  int nrows = dmt_size(md);
  int ind;
  double *col;
  loop_t* loop;
  int iind,isize,jsize;

  if (m->distribution == COLUMNS) mdtmp = md;
  else mdtmp = dmt_columns("dmt_mdescr_to_local_s scratch",md);

  loop = dmt_ngl_create("%mr",mdtmp);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&iind,&isize,&ind,&jsize,&col)) {
      for (j=0; j<nrows; j++) {
        if (j>=ind) data[j][ind] = col[j];
        }
      }
    }
  dmt_ngl_kill(loop);

  if (md != mdtmp) dmt_free(mdtmp);
}

@ This does the reverse of |dmt_mdescr_to_local_s|.  The |data|
argument points to the symmetric matrix and the |md| variable
is the target matrix descriptor.  The target matrix must currently
be |SCATTERED|.
@<Public higher level routines.@>=
GLOBAL_FUNCTION void
dmt_local_s_to_mdescr(data,md)
double **data;
mdescr md;
{
  int i,p,q;
  matrix *m = DECODE_DESCR(md);
  int nlocal = dmt_nlocal(md);
  int iblk,jblk,iblksz,jblksz,iblkstart,jblkstart;
  int idata,jdata;
  double *block;

  if (m->distribution != SCATTERED) {
    if (mynode0()==0) printf("dmt_local_s_to_mdescr requires SCATTERED\n");
    assert(0);
    }

  for (i=0; i<nlocal; i++) {
    dmt_get_block(md,i,&iblk,&jblk,&block);
    dmt_describe_block(md,iblk,&iblkstart,&iblksz);
    dmt_describe_block(md,jblk,&jblkstart,&jblksz);
    for (p=0; p<iblksz; p++) {
      for (q=0; q<jblksz; q++) {
        idata = iblkstart+p;
        jdata = jblkstart+q;
        if (jdata>idata) *block = data[jdata][idata];
        else             *block = data[idata][jdata];
        block++;
        }
      }
    }
}


@ Find the maximum absolute value in matrix |m1|.

@<Public higher level routines.@>=

GLOBAL_FUNCTION double
dmt_max_abs(m1)
mdescr m1;
{
    matrix *mp1 = DECODE_DESCR(m1);
    int ls = localsize (mp1);
    double rv, tmp;
    double *dat = mp1 -> data;
    int i;
    rv = 0.0;
    for (i=0; i<ls; i++) {
  	tmp = fabs (*dat++);
	if (tmp > rv) rv = tmp;
   }
   rv = lcl_gop(rv,'M',mtype_get());
   return (rv);
}

@ Compute the dot product of the elements of two matrices.

@<Public higher level routines.@>=

GLOBAL_FUNCTION double
dmt_adotb (m1, m2)
mdescr m1;
mdescr m2;
{
    matrix *mt1 = DECODE_DESCR (m1);
    matrix *mt2 = DECODE_DESCR (m2);
    double val =0.0;
    assert (mt1 -> distribution == mt2 -> distribution);
    if (mt1 -> distribution == COLUMNS) {
      int i, ls = localsize (mt1);
      double *dat1 = mt1 -> data, *dat2 = mt2 -> data;
      for (i = 0; i < ls; i++) val += (*dat1++) * (*dat2++);
      return (lcl_gop(val,'+',mtype_get()));
    }
    @<Do local val = A dot B for scattered matrices.@>;@/
    return (lcl_gop(val,'+',mtype_get()));
}


@ For scattered block distribution, the dot product must 
be careful to handle diagonal elements correctly.
@<Do local val = A dot B for scattered matrices.@>=
{
  map * mp = mt1 -> map_ptr;
  double *dat1, *dat2;
  int nl = mp -> nlocal_blocks;
  int i,j,il;
  for (il=0; il<nl; il++){
    dmt_get_block(m1, il, &i, &j, &dat1);
    dmt_get_block(m2, il, &i, &j, &dat2);
    if (i != j) {
      int ib, bs;
      short int *bvec = mp -> blksize;
      bs = bvec[i] * bvec[j];
      for (ib = 0; ib < bs; ib++) val += 2.0 * (*dat1++) * (*dat2++);
    } else {
      int sz = mp -> blksize [i];
      int ib, jb, ind;
      for (ib = 0; ib < sz; ib++){
	for (jb = 0; jb <= ib; jb++){
	  ind = ib * sz + jb;
	  if (ib == jb) val += dat1[ind] * dat2[ind];
	  else val += 2.0 * dat1[ind] * dat2[ind];
	}
      }
    }
  }
}

@ Set the diagonal values of a matrix from a vector.
@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_set_diagonal(m, diag)
mdescr m;
double *diag;
{
    matrix *mp = DECODE_DESCR(m);
    int nl = dmt_nlocal(m);
    if (mp->distribution == COLUMNS) {
      @<Set diagonal elts for column-distributed matrix.@>;
    } else {
      @<Set diagonal elts for scattered block matrix.@>;
    }
}

@ @<Set diagonal elts for column-distributed matrix.@>=
{
  int i, ind;
  double *col;
  for (i = 0; i < nl; i++) {
    dmt_get_col(m, i, &ind, &col);
    col[ind] = diag[ind];
  }
}

@ @<Set diagonal elts for scattered block matrix.@>=
{
  int i, ind, jnd, gind, len, ib;
  double *blk;
  for (i = 0; i < nl; i++) {
    dmt_get_block(m, i, &ind, &jnd, &blk);
    if (ind == jnd) {
      dmt_describe_block (m, ind, &gind, &len);
      for (ib = 0; ib < len; ib++) {
	*blk = diag[gind];
	blk += 1 + len;
	gind++;
      }
    }
  }
}

@ Get the diagonal values of a matrix from a vector.

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_get_diagonal(m, diag)
mdescr m;
double *diag;
{
    matrix *mp = DECODE_DESCR(m);
    int nl = dmt_nlocal(m);
    int i;

    for (i=0; i<mp->size; i++) {
      diag[i] = 0.0;
    }
    if (mp->distribution == COLUMNS) {
      @<Get diagonal elts for column-distributed matrix.@>;
    } else {
      @<Get diagonal elts for scattered block matrix.@>;
    }
    gsum0(diag,mp->size,5,mtype_get(),0);
    bcast0(diag,mp->size*sizeof(double),mtype_get(),0);
}

@ @<Get diagonal elts for column-distributed matrix.@>=
{
  int i, ind;
  double *col;
  for (i = 0; i < nl; i++) {
    dmt_get_col(m, i, &ind, &col);
    diag[ind] = col[ind];
  }
}

@ @<Get diagonal elts for scattered block matrix.@>=
{
  int i, ind, jnd, gind, len, ib;
  double *blk;
  for (i = 0; i < nl; i++) {
    dmt_get_block(m, i, &ind, &jnd, &blk);
    if (ind == jnd) {
      dmt_describe_block (m, ind, &gind, &len);
      for (ib = 0; ib < len; ib++) {
        diag[gind] = *blk;
	blk += 1 + len;
	gind++;
      }
    }
  }
}

@ Scale  the diagonal values of a matrix by a factor.

@<Public higher level routines.@>=


GLOBAL_FUNCTION void
dmt_scale_diagonal(m, scale)
mdescr m;
double scale;
{
    matrix *mp = DECODE_DESCR(m);
    int nl = dmt_nlocal(m);
    if (mp->distribution == COLUMNS) {
      @<Scale diagonal elts for column-distributed matrix.@>;
    } else {
      @<Scale diagonal elts for scattered block matrix.@>;
    }
}

@ @<Scale diagonal elts for column-distributed matrix.@>=
{
  int i, ind;
  double *col;
  for (i = 0; i < nl; i++) {
    dmt_get_col(m, i, &ind, &col);
    col[ind] *= scale;
  }
}

@ @<Scale diagonal elts for scattered block matrix.@>=
{
  int i, ind, jnd, ilen, jlen, ib;
  double *blk;
  for (i = 0; i < nl; i++) {
    dmt_get_block_dsc (m, i, &ind, &ilen, &jnd, &jlen, &blk);
    if (ind == jnd) {
      for (ib = 0; ib < ilen; ib++) {
	*blk *= scale;
	blk += 1 + ilen;
      }
    }
  }
}


@ Are the elements in a matrix essentially equal to those in another?

@<Public higher level routines.@>=

GLOBAL_FUNCTION booln
dmt_equal(m1, m2)
mdescr m1;
mdescr m2;
{
  assert (dmt_size(m1) == dmt_size(m2));
  if (dmt_distribution(m1) == dmt_distribution (m2)) {
    return (eql_mat (m1, m2));
  } else {
    mdescr tmp, t;
    booln rv;
    if (dmt_distribution (m1) == SCATTERED) {
      t = m2; tmp = dmt_columns("Temp for dmt_equal", m1);
    } else {
      t = m1; tmp = dmt_columns("Temp for dmt_equal", m2);
    }
    rv = eql_mat(t,tmp);
    dmt_free (tmp);
    return (rv);
  }
}

@ Are two same-distributed matrices equal?
@<Private support...@>=
LOCAL_FUNCTION booln
eql_mat(m1, m2)
mdescr m1;
mdescr m2;
{
  double *d1 = DECODE_DESCR(m1) -> data;
  double *d2 = DECODE_DESCR(m2) -> data;
  int ls = localsize (DECODE_DESCR(m1));
  int i;
  double val = 0.0;
  assert (ls == localsize (DECODE_DESCR (m2)));
  for (i = 0; i < ls; i++)
    if (fabs (*d1++ - *d2++) > 0.00001) val = 1.0;
  return (lcl_gop (val, 'M', mtype_get()) < 0.5);
}


@ Copy a matrix to another.


@<Public basic operations.@>=

GLOBAL_FUNCTION void
dmt_copy(src, dst) 
mdescr src;
mdescr dst;
{
    matrix *dm = DECODE_DESCR(dst); 
    matrix *sm = DECODE_DESCR(src);
    assert (dm -> map_ptr == sm -> map_ptr);
    if (dmt_distribution(src) == dmt_distribution (dst))
      dcopy (dm -> data, sm -> data, localsize(dm));
    else if (dmt_distribution(src) == SCATTERED)
      scatt_to_cols (src, dst);
    else cols_to_scatt(src, dst);
}

@ Fill matrix |m|  with |value|.

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_fill (m, value)
mdescr m;
double value;
{
    matrix *mp = DECODE_DESCR(m);
    dfill (mp -> data, value, localsize(mp));
}


@ Scale matrix |m|  with |value|.

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_scale (m, value)
mdescr m;
double value;
{
    matrix *mp = DECODE_DESCR(m);
    dscale (mp -> data, value, localsize(mp));
}


@ Sum matrix |m1| into matrix |m2|

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_sum (m1, m2)
mdescr m1;
mdescr m2;
{
    matrix *mp1 = DECODE_DESCR(m1);
    matrix *mp2 = DECODE_DESCR(m2);
    assert (localsize(mp1) == localsize(mp2));
    assert (mp1->distribution == mp2 -> distribution);
    daccum (mp2 -> data, mp1 -> data, localsize (mp1));
}

@ Sum |scale * m1| into m2.

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_sum_scaled (m1, scale, m2)
mdescr m1;
double scale;
mdescr m2;
{
    matrix *mp1 = DECODE_DESCR(m1);
    matrix *mp2 = DECODE_DESCR(m2);
    assert (localsize(mp1) == localsize(mp2));
    assert (mp1->distribution == mp2 -> distribution);
    dscaleaccum (mp2 -> data, scale, mp1 -> data, localsize (mp1));
  
}

@ Check to see if a square matrix is, in fact, symmetric.

@<Public higher level routines.@>=

GLOBAL_FUNCTION booln
dmt_symmp (m1) 
mdescr m1; 
{
  int n = dmt_size(m1);
  booln rval;
  mdescr temp = dmt_create("dmt_symmp temp mat", n, COLUMNS);
  dmt_copy (m1, temp); dmt_transpose (temp);
  rval = dmt_equal(m1, temp);
  dmt_free (temp);
  return (rval);
}

@ Check to see if a square matrix is, in fact, anti-symmetric.

@<Public higher level routines.@>=

GLOBAL_FUNCTION booln
dmt_asymmp (m1) 
mdescr m1; 
{
  int n = dmt_size(m1);
  booln rval;
  mdescr temp = dmt_create("dmt_symmp temp mat", n, COLUMNS);
  dmt_copy (m1, temp); dmt_transpose (temp);
  dmt_scale (temp, -1.0);
  rval = dmt_equal(m1, temp);
  dmt_free (temp);
  return (rval);
}



@ Check to see if a matrix of all zeros.

@<Public higher level routines.@>=

GLOBAL_FUNCTION booln
dmt_zerop (m1)
mdescr m1;
{
    matrix *mp1 = DECODE_DESCR(m1);
    register int i;
    int ls;
    double *d = mp1 -> data;
    double tmp = 0.0;

    ls = localsize(mp1);
    for (i=0; i<ls; i++) 
        if (*d++ != 0.0) {tmp = 1.0; break; }
    if (nproc > 1) tmp = lcl_gop (tmp, 'M', mtype_get()); 
    if (tmp > 0.5) return (FALSE);
    else return (TRUE);
}

@ Matrix transposition.  The matrix (which must be distributed by 
COLUMNS) is transposed in place.

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_transpose (m)
mdescr m;
{
  int localc, colind, rowind;
  int nlocal = dmt_nlocal (m);
  double *rowptr, *colptr;
  loop_t* loop;
  int ijunk,isz,junksz;
  assert (dmt_distribution (m) == COLUMNS);
  loop = dmt_ngl_create("%mr",m);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&ijunk,&isz,&colind,&junksz,&colptr)) {
      for (localc = 0; localc < nlocal; localc++){
        dmt_get_col(m, localc, &rowind, &rowptr);
        rowptr[colind] = colptr[rowind];
        }
      }
    }
  dmt_ngl_kill(loop);
}



@ Matrix multpilication.  This routine does not handle
all possible cases of types of matrices to multiply.
First of all, the output matrix must be in the 
|COLUMNS| distribution form.  
 The right-hand
matrix (is that the multiplier or the multiplicand?)
may be in either distrbution form, but you should know
that if it's |SCATTERED|, I'll convert it into a temporary
matrix of |COLUMNS|.  The left-hand matrix
may be in either column or scattered distribution.
However, if the left-hand matrix in distributed by
|COLUMNS|, then such columns should actually be rows.
This is true, of course, for symmetric matrices.  If your
matrix is non-symmetric, then you may need to use
|dmt_transpose|. 


@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_mult (a,b, product)
mdescr a;
mdescr b;
mdescr product;
{
  mdescr c = product;
  int convertedp = 0;
  assert (dmt_distribution(c) == COLUMNS);
  assert (c != b); assert (a != b); assert (a != c);
  TENTER ("dmt_mult");
  if (dmt_distribution (b) == SCATTERED) {
    b = dmt_columns ("dmt_mult temp mat", b);
    convertedp = 1;
  }
  if (dmt_distribution(a) == COLUMNS) {
    @<Matrix multiply for |a| by columns.@>;
  } else {
    @<Matrix multiply for |a| scattered.@>;
  }
  if (convertedp) dmt_free (b);
  TEXIT("dmt_mult");
}

@ The matrix multiply is most straightforward if all matrices are 
in column distribution.  Since the matrix |a| is symmetric,
column distribution is the same as row distribution.  Thus,
we'll implement the matrix multiply
$$
C_{ij} = \sum_{k} A_{ik}B_{kj}
$$
in the following way.  We have the rows (columns) of $A$, and we'll 
send these around the loop so that every processor sees every row of
$A$.  When we get such a row, say the $i^{th}$ row, for each local 
column $j$ that we have we'll form the product shown above.


@<Matrix multiply for |a| by columns.@>=
{
  int nl = dmt_nlocal(a);
  int n = dmt_size(a);
  double *row, *bcol, *ccol;
  int rowind, colind, il;
  int junkind,junksz,rowsz;
  loop_t* loop = dmt_ngl_create("%mr",a);

  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&junkind,&rowsz,&rowind,&junksz,&row)) {
      for (il = 0; il < nl; il++){ /* Use each local column. */
        dmt_get_col(b, il, &colind, &bcol);
        dmt_get_col(c, il, &colind, &ccol);
        ccol[rowind] = ddot (bcol, row, n);
      }
    }
  }
  dmt_ngl_kill(loop);
}

@ When the left-hand matrix $A$ is scattered, the scheme is much
the same.  We still pass around the $A$ blocks, forming the 
product as we do.  These fact that blocks get passed around
complicated indexing, and we must be careful with
the diagonal blocks of $A$.  Remember, we only pass
around the upper triangle of the symmetric matrix $A$ except
for these diagonal blocks which are full.

@<Matrix multiply for |a| scattered.@>=
{
  int nl = dmt_nlocal(b);
  int iblk, jblk, ibstart, jbstart, iblen, jblen, colind;
  int ib, jb, il;
  double *block, *bcol, *ccol, *bptr;
  loop_t* loop;

  dmt_fill (c, 0.0);
  loop = dmt_ngl_create("%mr",a);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&iblk,&iblen,&jblk,&jblen,&block)) {
      dmt_describe_block (a, iblk, &ibstart, &iblen);
      dmt_describe_block (a, jblk, &jbstart, &jblen);
      for (il = 0; il < nl; il ++) {
        dmt_get_col (b, il, &colind, &bcol);
        dmt_get_col (c, il, &colind, &ccol);
        bptr = block;
        for (ib = 0; ib < iblen; ib++){  /* Use each element of the block. */
          for (jb = 0; jb < jblen; jb++){
            ccol[ibstart+ib] += *bptr * bcol[jbstart+jb];
            if(iblk != jblk) ccol[jbstart+jb] += *bptr * bcol[ibstart+ib];
            bptr++;
            }
          }
        }
      }
    }
  dmt_ngl_kill(loop);
}

@ Diagonalize a matrix.

@<Public higher level routines.@>=

GLOBAL_FUNCTION void
dmt_diag(m, vec, val)
mdescr m;
mdescr vec;
double *val;
{
  @<Decls for |diag|.@>;
  TENTER("dmt_diag");
  @<Error checking for |diag|.@>;
  @<Copy columns  from |m| into |A| for |diagonal_|@>;
  diagonal_ (&iochan, &nbasis, &diag_nlocal, A, val, e, sigma, Z, Z, w, indary);
  @<Copy eigenvectors |Z| into |vec|.@>;
  @<Deallocate temporary storage for |diag|.@>;
  TEXIT("dmt_diag");
}


@ Let's start assembling the calling paramters to
|diagonal_|.  First various integer values. |nbasis| is
the matrix size.  |nlocal| is the number of locally
held columns of the matrix in the |dmt_| distribution
scheme.  |diag_nlocal| is the corresponding value in
the distribution scheme used by |diagonal_|.  |indary|
is some vector required by the diagonalizer, and
|ilocal| keeps a list of the indices of the locally
held columns of the matrix in the new distribution.

@<Decls for |diag|.@>=
    int nbasis = dmt_size(m);
    int nlocal = dmt_nlocal(m);
    int diag_nlocal = ((me < (nbasis % nproc)) ?
         nbasis / nproc + 1 : nbasis / nproc);
    int *indary = (int *) Malloc(nbasis * sizeof (int));
    int *ilocal = (int *) Malloc ((nlocal+1) * sizeof (int));
    extern void diagonal_();

@ Free the integer vector when we're done.
@<Deallocate temporary storage...@>=
    Free ((char *) indary);
    Free ((char *) ilocal);


@ Now, allocate the floating-point storage.
@<Decls for |diag|.@>=
    double *A = (double *) Malloc ( nbasis * diag_nlocal * sizeof(double));
    double *e = (double *) Malloc ( nbasis * sizeof(double));
    double *sigma = (double *) Malloc ( nbasis * sizeof(double));
    double *Z = (double *) Malloc ( diag_nlocal * nbasis * sizeof(double));
    double *w = (double *) Malloc ( 5 * nbasis * sizeof(double));
    
@ Free the FP storage when we're done.
@<Deallocate temporary storage...@>=
     Free (A);
     Free (e);
     Free (sigma);
     Free (Z);
     Free (w);

@ Make sure that all of the  memory allocation worked.
@<Error checking for |diag|.@>=
{
    check_alloc (A , "A ");
    check_alloc (e , "e ");
    check_alloc (sigma , "sigma ");
    check_alloc (Z , "Z ");
    check_alloc (w , "w ");
    check_alloc (indary , "indary ");
    check_alloc (ilocal , "ilocal ");
    assert (dmt_distribution(m) == COLUMNS);
    assert (dmt_distribution(vec) == COLUMNS);
}

@ We must now copy the data in the matrix |m| into the locally
allocated columns of the matrix |A|.  The Fortran routine |diagonal|
expects to have the |nlocal| columns of the matrix to be diagonalized
as the calling argument.  However, the distribution that |diagonal|
expects is different than that uset by \.{dmt\_pack}.  Thus, we 
first use the loop to re-distribute the columns into the proper order.

@<Copy columns  from |m| into |A| for |diagonal_|@>=
{
  int ngot = 0; /* Number of columns we've gotten from loop. */
  int index;
  double *colptr;
  loop_t* loop;
  int iind,isize,jsize;

  @<Fill |ilocal| with list of |diag| local indices.@>; @/

  loop = dmt_ngl_create("%mr",m);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&iind,&isize,&index,&jsize,&colptr)) {
      if ((index % nproc) == me) {
        @<Copy loop column |index| into |A| according to |ilocal|.@>;
        ngot++;
        }
      }
    }
  dmt_ngl_kill(loop);
}

@ We fill |ilocal| with the list of columns held
locally for the distribution scheme required by
|diagonal_|.

@<Fill |ilocal| with list of |diag| local indices.@>=
{
  int i, nl = 0;
  for (i = 0; i < nbasis; i ++){
    if ((i % nproc) == me) ilocal[nl++] = i;
  }

#if defined(DBG_DUMP)
  {
    int k;
    printf ("%d: i have locals: ", mynode0());
    for (k=0;k<nl;k++) printf (" %d ", ilocal[k]);
    printf ("\n");
  }
#endif
  assert (nl == diag_nlocal);
}

@ The incoming column must be copied into the correct
location in the local storage.  We search through
|ilocal| to identify the correct location.

@<Copy loop column |index| into |A| according to |ilocal|.@>=
{
  static int il;
  for (il = 0; il < diag_nlocal; il++) {
    if (index == ilocal[il]) {
      dcopy(A + (nbasis*il), colptr, nbasis);
#if 0
      printf("Node %d local column %d: % 12.8lf % 12.8lf % 12.8lf % 12.8lf",
             mynode0(),il,
             (A+(nbasis*il))[0],
             (A+(nbasis*il))[1],
             (A+(nbasis*il))[2],
             (A+(nbasis*il))[3]);
#endif
      break;
    }
  }

  assert (il < diag_nlocal);
}

@ We now need to copy the returned eigenvectors |Z| into the required
output matrix |vec|.  We do this by putting |vec| onto the 
loop.  Each node then copies its local vectors onto the loop to be
sent back around to the owner.

@<Copy eigenvectors |Z| into |vec|.@>=
{
  int index;
  double *colptr;
  int nput = 0; /* Count the number of vectors we put onto the loop. */
  loop_t* loop;
  int iind,isize,jsize;

  dmt_fill (vec, 0.0); /* initialize the vector */

  loop = dmt_ngl_create("%m",vec);
  while(dmt_ngl_next(loop)) {
    dmt_ngl_create_inner(loop,0);
    while(dmt_ngl_next_inner_m(loop,&iind,&isize,&index,&jsize,&colptr)) {
      if (index%nproc==me){/* If this is a column I have, copy it onto the loop. */
        @<Copy column |index| from |Z| to |colptr|.@>;
        nput++;
        }
      }
    }
  dmt_ngl_kill(loop);
}

@ @<Copy column |index| from |Z| to |colptr|.@>=
{
  int j, gotit = 0;
  for (j = 0; j < diag_nlocal; j++){
    if (ilocal[j] == index) {
      dcopy (colptr, Z+j*nbasis, nbasis);
      gotit = 1;
#ifdef DBG_DUMP
      {
	int k;
	printf ("eigenvector (%d): ", index);
	for (k=0; k<nbasis; k++) printf (" %f ", Z[j*nbasis + k]);
	printf ("\n");
      }
#endif
      break;
    }
  }
  assert (gotit);
  assert (j < diag_nlocal);
}

@* Nestable general loop routines.  These routines will hopefully
provide all the support that is needed for any (reasonable)
loop needs.  These are varargs functions, with a syntax
much like |printf| in the standard C library.
One would call |dmt_ngl_create()| with a format string, followed
by an arbitrary number of things to put on the loop. Legal
format specifiers are (more to follow if necessary):

\item{|%m|} Dmt matrix.
\item{|%mr|} Read only dmt matrix.
\item{|%smr|} Sparse dmt matrix.  Sparse data can only be read and not written.
\item{|%smrt|} Sparse dmt matrix with threshold information.  Threshold information
             is never updated.
\item{|%am|} Array and dmt matrix.
\item{|%armr|} Read only array and read only dmt matrix.
\item{|%sarmr|} Sparse array and dmt matrix.
\item{|%sarmrt|} Sparse array and dmt matrix with threshold information.

All arrays are read only and all sparse data is read only.  I don't
enforce this with |const| however, so it is up to the programmer to not
update read only data.  Writing to read only data may produce very
unpredictable results, since at some point I will be forwarding loop
data to reduce the effect of loop synchronization on processor utilization.


@<Nestable general loop routines.@>=

 @<Nestable general loop public routines.@> @/
 @<Nestable general loop private routines.@> @/

@ First let's define some things that we'll need later.

@<Decls for ngl@>=

#define NGL_M 1
#define NGL_SM 2
#define NGL_AM 3
#define NGL_SAM 4

static loop_t *ngl_stack = NULL;
static int ngl_loop_id = 0;

@ Now let's form the loop.

@<Nestable general loop public routines.@>=

GLOBAL_VA_FUNCTION loop_t *
#ifndef __STDC__
dmt_ngl_create(fmt)
char *fmt;
#else
dmt_ngl_create(char *fmt, ...)
#endif
{
  int offset;
  va_list args;
  char tmp[512],*tok;
  int ndouble=0, nint=0; /* Allocation sizes. */
  int bufsize;
  int i,j,k;
  int *ibuf;
  double *rbuf;

  /* Set up the stack to point to this new loop. */
  ngl_push();

  if((int) strlen(fmt) >= 512) {
    fprintf(stderr,"ERROR: dmt_ngl_create: fmt(=\"%s\") too long",fmt);
    assert(0); fatal();
    }

  strcpy(tmp,fmt);

  va_start(args,fmt);

  tok=strtok(tmp," \t\n");

  ngl_stack->readonly = 1;

  while(tok) {
    ngl_stack->args[ngl_stack->nargs].t = NULL;
    if(!strcmp(tok,"%m")||!strcmp(tok,"%mr")) {
      ngl_stack->args[ngl_stack->nargs].type = NGL_M;
      ngl_stack->args[ngl_stack->nargs].m = va_arg(args,mdescr);
      ndouble += ngl_doublesize(ngl_stack->args[ngl_stack->nargs].m);
      nint += ngl_intsize(ngl_stack->args[ngl_stack->nargs].m);
      ngl_stack->args[ngl_stack->nargs].readonly = (tok[2] == 'r'?1:0);
      }
    else if(!strcmp(tok,"%arm")||!strcmp(tok,"%armr")) {
      ngl_stack->args[ngl_stack->nargs].type = NGL_AM;
      ngl_stack->args[ngl_stack->nargs].a = va_arg(args,double*);
      ngl_stack->args[ngl_stack->nargs].m = va_arg(args,mdescr);
      ndouble += ngl_doublesize(ngl_stack->args[ngl_stack->nargs].m);
      nint += ngl_intsize(ngl_stack->args[ngl_stack->nargs].m);
      ndouble += dmt_nlocal(ngl_stack->args[ngl_stack->nargs].m);
      ngl_stack->args[ngl_stack->nargs].readonly = (tok[4] == 'r'?1:0);
      }
    else if(!strcmp(tok,"%smr")) {
      ngl_stack->args[ngl_stack->nargs].type = NGL_SM;
      ngl_stack->args[ngl_stack->nargs].m = va_arg(args,mdescr);
      ngl_stack->args[ngl_stack->nargs].readonly = 1;
      ndouble += ngl_sigdoublesize(ngl_stack->args[ngl_stack->nargs].m);
      nint += ngl_sigintsize(ngl_stack->args[ngl_stack->nargs].m);
      }
    else if(!strcmp(tok,"%sarmr")) {
      ngl_stack->args[ngl_stack->nargs].type = NGL_SAM;
      ngl_stack->args[ngl_stack->nargs].a = va_arg(args,double*);
      ngl_stack->args[ngl_stack->nargs].m = va_arg(args,mdescr);
      ngl_stack->args[ngl_stack->nargs].readonly = 1;
      ndouble += ngl_sigdoublesize(ngl_stack->args[ngl_stack->nargs].m);
      nint += ngl_sigintsize(ngl_stack->args[ngl_stack->nargs].m);
      ndouble += ngl_nsiglocal(ngl_stack->args[ngl_stack->nargs].m);
      }
    else if(!strcmp(tok,"%smrt")) {
      ngl_stack->args[ngl_stack->nargs].type = NGL_SM;
      ngl_stack->args[ngl_stack->nargs].m = va_arg(args,mdescr);
      ngl_stack->args[ngl_stack->nargs].t = va_arg(args,double*);
      ngl_stack->args[ngl_stack->nargs].readonly = 1;
      ndouble += ngl_sigdoublesizet(ngl_stack->args[ngl_stack->nargs].m,
                                    ngl_stack->args[ngl_stack->nargs].t);
      nint += ngl_sigintsizet(ngl_stack->args[ngl_stack->nargs].m,
                              ngl_stack->args[ngl_stack->nargs].t);
      }
    else if(!strcmp(tok,"%sarmrt")) {
      ngl_stack->args[ngl_stack->nargs].type = NGL_SAM;
      ngl_stack->args[ngl_stack->nargs].a = va_arg(args,double*);
      ngl_stack->args[ngl_stack->nargs].m = va_arg(args,mdescr);
      ngl_stack->args[ngl_stack->nargs].t = va_arg(args,double*);
      ngl_stack->args[ngl_stack->nargs].readonly = 1;
      ndouble += ngl_sigdoublesizet(ngl_stack->args[ngl_stack->nargs].m,
                                    ngl_stack->args[ngl_stack->nargs].t);
      nint += ngl_sigintsizet(ngl_stack->args[ngl_stack->nargs].m,
                              ngl_stack->args[ngl_stack->nargs].t);
      ndouble += ngl_nsiglocalt(ngl_stack->args[ngl_stack->nargs].m,
                                ngl_stack->args[ngl_stack->nargs].t);
      }
    else {
      fprintf(stderr,"ERROR: dmt_ngl_create: invalid code \"%s\"\n",tok);
      assert(0); fatal();
      }
    ngl_stack->readonly =     ngl_stack->readonly
                          && ngl_stack->args[ngl_stack->nargs].readonly;

    ngl_stack->nargs++;

    if(ngl_stack->nargs==MAXARGS) {
      fprintf(stderr,"ERROR: dmt_make_gen_loop: too many arguments\n");
      assert(0); fatal();
      }

    tok=strtok(NULL," \t\n");
    }

  va_end(args);

  /* Space for the origin information (for error checking). */
  nint++;

  /* Align the data. */
  if (nint & 1) nint++;

#if 0
  printf("nint = %d, ndouble = %d\n",nint,ndouble);
#endif

  /* Find the largest buffer on any node. */
  bufsize = nint*sizeof(int) + ndouble*sizeof(double);
  ngl_stack->current_bufsize = bufsize;
  gmax0(&bufsize,1,2,mtype_get(),0);
  bcast0(&bufsize,sizeof(int),mtype_get(),0);
  ngl_stack->total_bufsize = bufsize;

  /* Allocate a buffer for the data. */
  ngl_stack->buf = (void *)malloc(bufsize);
  check_alloc(ngl_stack->buf,"ngl_stack->buf");
  ibuf = (int *) ngl_stack->buf;
  rbuf = (double *) ngl_stack->buf;

  /* Copy the data into the buffer. */
  /* The origin is stored for error checking. */
  *ibuf++ = me;
  offset = nint/2; /* Assumes sizeof(int)*2 == sizeof(double) */
  rbuf = &rbuf[offset];
  for (i=0; i<ngl_stack->nargs; i++) {
    ngl_descr_t ngl;
    int *nlocal = ibuf++;
    int imat, jmat, isz, jsz, size;
    double *data;
    ngl = ngl_stack->args[i];
    *nlocal = 0;
    for (j=0; j<dmt_nlocal(ngl.m); j++) {
      if (   (ngl.type == NGL_SM || ngl.type == NGL_SAM)
          && dmt_is_local_zero(ngl.m,j)) continue;

      /* Set up the data in the integer part of the buffer. */
      if (dmt_distribution(ngl.m) == COLUMNS) {
        dmt_get_col(ngl.m,j,&jmat,&data);
        size = dmt_size(ngl.m);
        (*nlocal)++;
        *ibuf++ = 1;
        *ibuf++ = size;
        *ibuf++ = jmat;
        *ibuf++ = 1;
        *ibuf++ = offset;
        }
      else if (dmt_distribution(ngl.m) == SCATTERED) {
        dmt_get_block_dsc(ngl.m,j,&imat,&isz,&jmat,&jsz,&data);
        (*nlocal)++;
        *ibuf++ = imat;
        *ibuf++ = isz;
        *ibuf++ = jmat;
        *ibuf++ = jsz;
        *ibuf++ = offset;
        size = isz * jsz;
        }

      /* Set up the data in the real part of the buffer. */

      /* The array data (if any) precedes the corresponding dmt data. */
      if ((ngl.type == NGL_AM) || (ngl.type == NGL_SAM)) {
#if 0
        printf("array at 0x%x ",rbuf);
#endif
        *rbuf++ = ngl.a[j];
        offset++;
        }
      else {
#if 0
        printf("                    ");
#endif
        }

      /* The dmt data. */
#if 0
      printf("dmt (arg=%d,ilocal=%d) at 0x%x\n",i,j,rbuf);
#endif
      for (k=0; k<size; k++) {
        *rbuf++ = *data++;
        }
      offset += size;
      }
    }

  /* Prime the loop if throttling is used. */
  for (i=0; i<throttle; i++) {
    send0(ngl_stack->buf,ngl_stack->current_bufsize,ngl_stack->smsgtype++,out_neigh_list[i]);
    }

  n_sync = 0;

  return ngl_stack;
  }

@ Compute the size of the double part of the buffer for the
given matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_doublesize(M)
mdescr M;
{
  int ssize;
  if (dmt_distribution(M) == COLUMNS) {
    ssize = dmt_size(M) * dmt_nlocal(M);
    }
  else {
    int i;
    int bsize;
    for (i=0,ssize=0; i<dmt_nlocal(M); i++) {
      int imat,isz,jmat,jsz;
      double *data;
      dmt_get_block_dsc(M,i,&imat,&isz,&jmat,&jsz,&data);
      bsize = isz * jsz;
      ssize += bsize;
      }
    }
#if 0
  printf("ngl_doublesize: returning %d\n",ssize);
#endif
  return ssize;
  }

@ Compute the size of the integer part of the buffer for the
given matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_intsize(M)
mdescr M;
{
  return 1 + 5 * dmt_nlocal(M);
  }

@ Compute the number of significant blocks (or columns) among the
locally held data for a dmt matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_nsiglocal(M)
mdescr M;
{
  int i,size=0;
  for (i=0; i<dmt_nlocal(M); i++) {
    if (dmt_is_local_zero(M,i)) continue;
    size++;
    }
#if 0
  printf("ngl_nsiglocal: returning %d\n",size);
#endif
  return size;
  }

@ Compute the size of the double part of the buffer for the
given sparse matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_sigdoublesize(M)
mdescr M;
{
  int i,size=0;
  int bsize;
  for (i=0; i<dmt_nlocal(M); i++) {
    if (dmt_is_local_zero(M,i)) continue;
    if (dmt_distribution(M) == COLUMNS) {
      size += dmt_nlocal(M);
      }
    else {
      int imat,isz,jmat,jsz;
      double *data;
      dmt_get_block_dsc(M,i,&imat,&isz,&jmat,&jsz,&data);
      bsize = isz * jsz;
      size += bsize;
      }
    }
#if 0
  printf("ngl_sgidoublesize: returning %d\n",size);
#endif
  return size;
  }

@ Compute the size of the integer part of the buffer for the
given sparse matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_sigintsize(M)
mdescr M;
{
  int i,size=0;
  for (i=0; i<dmt_nlocal(M); i++) {
    if (dmt_is_local_zero(M,i)) continue;
    size += 5;
    }
  return size + 1;
  }

@ Compute the number of significant blocks (or columns) among the
locally held data for a dmt matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_nsiglocalt(M,t)
mdescr M;
double *t;
{
  int i,size=0;
  for (i=0; i<dmt_nlocal(M); i++) {
    if (dmt_magnitude(M,i) < t[i]) continue;
    size++;
    }
#if 0
  printf("ngl_nsiglocal: returning %d\n",size);
#endif
  return size;
  }

@ Compute the size of the double part of the buffer for the
given sparse matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_sigdoublesizet(M,t)
mdescr M;
double *t;
{
  int i,size=0;
  int bsize;
  for (i=0; i<dmt_nlocal(M); i++) {
    if (dmt_magnitude(M,i) < t[i]) continue;
    if (dmt_distribution(M) == COLUMNS) {
      size += dmt_nlocal(M);
      }
    else {
      int imat,isz,jmat,jsz;
      double *data;
      dmt_get_block_dsc(M,i,&imat,&isz,&jmat,&jsz,&data);
      bsize = isz * jsz;
      size += bsize;
      }
    }
#if 0
  printf("ngl_sgidoublesize: returning %d\n",size);
#endif
  return size;
  }

@ Compute the size of the integer part of the buffer for the
given sparse matrix.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_sigintsizet(M,t)
mdescr M;
double *t;
{
  int i,size=0;
  for (i=0; i<dmt_nlocal(M); i++) {
    if (dmt_magnitude(M,i) < t[i]) continue;
    size += 5;
    }
  return size + 1;
  }

@ Determine if the specified locally held block is zero.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
dmt_is_local_zero(M,lind)
mdescr M;
int lind;
{
  int i;
  int imat,jmat,isz,jsz,size;
  double *data;

  if (dmt_distribution(M) == COLUMNS) {
    dmt_get_col(M,lind,&imat,&data);
    size = dmt_size(M);
    }
  else {
    dmt_get_block_dsc(M,lind,&imat,&isz,&jmat,&jsz,&data);
    size = isz*jsz;
    }

  for (i=0; i<size; i++) {
    if (fabs(data[i]) > 1.0e-10) {
      return 0;
      }
    }
  return 1;
  }

@ Return the magnitude of the largest element in block |lind| in matrix |M|.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION double
dmt_magnitude(M,lind)
mdescr M;
int lind;
{
  int i;
  int imat,jmat,isz,jsz,size;
  double *data;
  double max = 0.0;

  if (dmt_distribution(M) == COLUMNS) {
    dmt_get_col(M,lind,&imat,&data);
    size = dmt_size(M);
    }
  else {
    dmt_get_block_dsc(M,lind,&imat,&isz,&jmat,&jsz,&data);
    size = isz*jsz;
    }

  for (i=0; i<size; i++) {
    if (fabs(data[i]) > max) {
      max = fabs(data[i]);
      }
    }
  return max;
  }

@ Push a new loop onto the stack.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION void
ngl_push()
{
  loop_t *old = ngl_stack;

  ngl_stack = (loop_t*) malloc(sizeof(loop_t));
  check_alloc(ngl_stack,"ngl_stack");

  ngl_stack->nargs = 0;
  ngl_stack->loop_count = 0;
  ngl_stack->smsgtype = ngl_stack->rmsgtype = MTYPE_NGL + ngl_loop_id++ * 100;
  if (ngl_loop_id > 10) ngl_loop_id = 0;
  ngl_stack->p = old;
  }

@ Pop a new loop from the stack.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION void
ngl_pop()
{
  loop_t *old = ngl_stack;

  if (!old) {
    fprintf(stderr,"ngl_pop called with empty stack\n");
    assert(0); fatal();
    }

  ngl_stack = old->p;
  free(old);
  }

@ This requests that the current loop buffer be sent to the
next neighbor and a new one be received from the previous neighbor.
This returns |1| if there is data to process and |0| if no more
data remains to be processed.  This function must only be called
after a loop has been created with |dmt_ngl_create()|.  If
|dmt_ngl_next()| returns |0|, but is called again before
|dmt_ngl_kill()|, then the loop will start again from the beginning.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION int
dmt_ngl_next(loop)
loop_t *loop;
{
  int type,source;
  int sync;

  if (most_distant_out_neigh == -1) dmt_set_throttle(0);

  if (!loop) loop = ngl_stack;

  if (loop->loop_count == 0) {
    loop->loop_count++;
    return 1;
    }

  if (loop->loop_count == nproc) {
    loop->loop_count = -1;
    return 0;
    }

  if(sync_loop!=-1) {
    /* Tell the in neigh that a block is being processed. */
    send0(&sync,sizeof(sync),MTYPE_LOOPSYNC,most_distant_in_neigh);

    /* If a sync is needed, do it. */
    if(n_sync >= sync_loop) {
      recv0(&sync,sizeof(sync),MTYPE_LOOPSYNC);
      }
    else {
      n_sync++;
      }
    }

  send0(loop->buf,loop->current_bufsize,loop->smsgtype++,most_distant_out_neigh);
  recv0(loop->buf,loop->total_bufsize,loop->rmsgtype++);
  recvinfo0(&loop->current_bufsize,&type,&source);

  if (loop->loop_count == -1) loop->loop_count = 0;

  loop->loop_count++;
  return 1;
  }

@ This terminates the current loop and frees the allocated storage.
It can only be called after |dmt_ngl_create()| has been called
to create a loop and should be called whenever the programmer is
finished with a loop.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION void
dmt_ngl_kill(loop)
loop_t *loop;
{
  int i,sync;

  if (!loop) loop = ngl_stack;

  if (loop != ngl_stack) {
    printf("dmt_ngl_kill: loops should be killed in the order they");
    printf("were created (for now)\n");
    assert(0);
    }

  /* Remove ungrabbed sync messages. */
  if (sync_loop!=-1) {
    for (i=0; i<n_sync; i++) {
      recv0(&sync,sizeof(sync),MTYPE_LOOPSYNC);
      }
    }

  ngl_update_local_data(loop);
  free(loop->buf);
  ngl_pop();
  }

@ This routine creates a loop over locally held loop data.
The argument is the number of the array which will drive the loop structure.
This number is determined by the position it appeared in the
format given to |dmt_ngl_create|.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION void
dmt_ngl_create_inner(loop,num)
loop_t *loop;
int num;
{
  if (!loop) loop = ngl_stack;
  loop->innerloopmat = num;
  loop->nextblock = 0;
  }

@ This routine iterates over the locally held loop data.
The |dmt_ngl_create_inner| routine must be called first.
This will return |1| if there is more data to be processed
and |0| otherwise.  If the array has |COLUMNS| distribution,
then it is treated like a |SCATTERED| matrix with a row address
of |1|.
A pointer to the dmt data is
written to the last argument.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION int
dmt_ngl_next_inner_m(loop,imat,isz,jmat,jsz,dmtdata)
loop_t *loop;
int *imat;
int *isz;
int *jmat;
int *jsz;
double **dmtdata;
{
  int offset;
  double *rbuf;

  if (!loop) loop = ngl_stack;

  rbuf = loop->buf;

  if (!ngl_next_inner(loop,imat,isz,jmat,jsz,&offset)) return 0;
  *dmtdata = &rbuf[offset];
  if (  (loop->args[loop->innerloopmat].type == NGL_AM)
      ||(loop->args[loop->innerloopmat].type == NGL_SAM)) {
    (*dmtdata)++;
    }
  return 1;
  }

@ This is like |dmt_ngl_next_inner_m|, but also has a pointer to the
array data updated.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION int
dmt_ngl_next_inner_am(loop,imat,isz,jmat,jsz,adata,dmtdata)
loop_t *loop;
int *imat;
int *isz;
int *jmat;
int *jsz;
double **adata;
double **dmtdata;
{
  int offset;
  double *rbuf;

  if (!loop) loop = ngl_stack;

  rbuf = loop->buf;
  if (!ngl_next_inner(loop,imat,isz,jmat,jsz,&offset)) return 0;
  *adata = &rbuf[offset];
  *dmtdata = &rbuf[offset+1];
  return 1;
  }

@ This routine retrieves a block from the loop.  If it is not currently
on this node or is not included at because its elements are zero, then
zero is returned.  Otherwise one is returned.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION int
dmt_ngl_find_m(loop,dmtmat,imat,jmat,data)
loop_t *loop;
int dmtmat;
int imat;
int jmat;
double **data;
{
  int block = ngl_get_block_number(loop,dmtmat,imat,jmat);

  if (!loop) loop = ngl_stack;

  if (block == -1) {
    *data = NULL;
    return 0;
    }

  *data = ngl_access_dmt(loop,dmtmat,block);
  return 1;
  }

@ This routine retrieves a block from the loop.  If it is not currently
on this node or is not included or its elements are zero, then
zero is returned.  Otherwise one is returned.
@<Nestable general loop public routines.@>=
GLOBAL_FUNCTION int
dmt_ngl_find_am(loop,dmtmat,imat,jmat,adata,dmtdata)
loop_t *loop;
int dmtmat;
int imat;
int jmat;
double *adata;
double **dmtdata;
{
  int block = ngl_get_block_number(loop,dmtmat,imat,jmat);

  if (!loop) loop = ngl_stack;

  if (block == -1) return 0;

  *dmtdata = ngl_access_array(loop,dmtmat,block);
  *adata = **dmtdata;
  (*dmtdata)++;
  return 1;
  }

@ This routine converts an i and j number to a block number.
If the block is not found, then |-1| is returned.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_get_block_number(loop,dmtmat,imat,jmat)
loop_t *loop;
int dmtmat;
int imat;
int jmat;
{
  int *ibuf;
  int i,n;

  if (!loop) loop = ngl_stack;

  ibuf = loop->buf;

  ibuf++;
  for (i=0; i<dmtmat; i++) ibuf += 5 * *ibuf + 1;

  n = *ibuf++;
  for (i=0; i<n; i++) {
#if 0
    printf("ngl_get_block_number: testing (%d,%d) == (%d,%d)\n",
           ibuf[0],ibuf[2],imat,jmat);
#endif
    if (ibuf[0] == imat && ibuf[2] == jmat) {
#if 0
      printf("ngl_get_block_number: returning %d\n",i);
#endif
      return i;
      }
    ibuf += 5;
    }

  return -1;
  }

@ This routine extracts dmt data from the buffer.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION double *
ngl_access_dmt(loop,dmtmat,dmtblock)
loop_t *loop;
int dmtmat;
int dmtblock;
{
  double *r;

  if (!loop) loop = ngl_stack;

  r = ngl_access_array(loop,dmtmat,dmtblock);

  if (  (loop->args[dmtmat].type == NGL_AM)
      ||(loop->args[dmtmat].type == NGL_SAM)) {
    r++;
    }

  return r;
  }

@ If the matrix indicated in argument one has an associated array,
then a pointer to the array is returned.  Otherwise, a pointer to
the dmt data is returned.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION double *
ngl_access_array(loop,dmtmat,dmtblock)
loop_t *loop;
int dmtmat;
int dmtblock;
{
  int *ibuf;
  double *rbuf;
  int i;

  if (!loop) loop = ngl_stack;

  ibuf = loop->buf;
  rbuf = loop->buf;

  ibuf++;
  for (i=0; i<dmtmat; i++) ibuf += 5 * *ibuf + 1;
  ibuf++;

  ibuf += 5* dmtblock + 4;

  return rbuf + *ibuf;
  }

@ This routine grabs any remaining blocks off of the loop and
calls |ngl_do_update| to accumulate the data to its original
storage area.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION void
ngl_update_local_data(loop)
loop_t *loop;
{
  int i;
  int type,source;

  if (!loop) loop = ngl_stack;

  assert(loop->loop_count == -1);

  /* Send out local data to where it belongs. */
  send0(loop->buf,loop->current_bufsize,loop->smsgtype++,*(int*)loop->buf);

  /* Receive loop blocks and send them off to where they go. */
  for (i=0; i<throttle; i++) {
    recv0(loop->buf,loop->total_bufsize,loop->rmsgtype++);
    recvinfo0(&loop->current_bufsize,&type,&source);
    send0(loop->buf,loop->current_bufsize,loop->smsgtype++,*(int*)loop->buf);
    }

  /* Accumulate the loop blocks that we have been sent. */
  for (i=0; i<=throttle; i++) {
    recv0(loop->buf,loop->total_bufsize,loop->rmsgtype++);
    recvinfo0(&loop->current_bufsize,&type,&source);
    ngl_do_update(loop);
    }

  }

@ This routine copies writable data from the loop back into the locally
head blocks in memory.  It does not overwrite the local data; it accumulates
into the local data.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION void
ngl_do_update(loop)
loop_t *loop;
{
  int i,j,k;
  mdescr M;
  double *data,*loopdata;
  int size;
  int imat,jmat,isz,jsz;
  int *ibuf;

  if (!loop) loop = ngl_stack;

  ibuf = loop->buf;

  if (*ibuf != me) {
    printf(" on %d: tried to update data for node %d\n",me,*ibuf);
    exit(1);
    }

  for (i=0; i<loop->nargs; i++) {
    if (loop->args[i].readonly) continue;
    M = loop->args[i].m;
    for (j=0; j<dmt_nlocal(M); j++) {
      loopdata = ngl_access_array(loop,i,j);
      if (loop->args[i].type == NGL_AM) {
        loop->args[i].a[j] = *loopdata++;
        }
      if (dmt_distribution(M) == COLUMNS) {
        dmt_get_col(M,j,&jmat,&data);
        size = dmt_size(M);
        }
      else {
        dmt_get_block_dsc(M,j,&imat,&isz,&jmat,&jsz,&data);
        size = isz*jsz;
        }
      for (k=0; k<size; k++) *data++ += *loopdata++;
      }
    }
  }

@ This finds the indices to the next inner loop block.
@<Nestable general loop private routines.@>=
LOCAL_FUNCTION int
ngl_next_inner(loop,imat,isz,jmat,jsz,offset)
loop_t *loop;
int *imat;
int *isz;
int *jmat;
int *jsz;
int *offset;
{
  int *ibuf;
  int i;

  if (!loop) loop = ngl_stack;

  ibuf = loop->buf;

#if 0
  printf("ngl_next_inner: nextblock = %d\n",loop->nextblock);
  printf("ngl_next_inner: innerloopmat = %d\n",loop->innerloopmat);
#endif

  ibuf++;
  for (i=0; i<loop->innerloopmat; i++) {
#if 0
    printf("ngl_next_inner: got nlocal = %d\n",*ibuf);
#endif
    ibuf += 5 * *ibuf + 1;
    }

#if 0
  printf("ngl_next_inner: got final nlocal = %d\n",*ibuf);
#endif

  if (*ibuf <= loop->nextblock) {
    loop->nextblock = 0;
    return 0;
    }

  ibuf += 5* loop->nextblock + 1;

  *imat = *ibuf++;
  *isz = *ibuf++;
  *jmat = *ibuf++;
  *jsz = *ibuf++;
  *offset = *ibuf++;

#if 0
  printf("ngl_next_inner: imat,isz,jmat,jsz = %d,%d,%d,%d\n",
         *imat,*isz,*jmat,*jsz);
#endif
  
  loop->nextblock++;
  return 1;
  }

@* Sparse matrix routines.  The idea is that as we treat larger and
larger systems, the degree of localization of interactions between
different parts of the molecules will increase.  Thus, it is anticipated
that efficiently dealing with sparse matrices will eventually be
important.  This section provides routines for the analysis and
manipulation of sparse matrices.

@<Sparse matrix routines.@>=

 @<Sparse matrix initialization.@> @/
 @<Sparse matrix public routines.@> @/

@ The smallest elements have $log_{10} abs(M_{ij}) <=$
|ELEMENTS_START| and are all grouped together.  The rest of the
elements are grouped into the other |MAX_ELEMENTS|.

@<Sparse matrix initialization.@>=
#define ELEMENT_START -19
#define MAX_ELEMENTS   20

@ This routine classifies the elements of the matrix by $log_{10}$.
A summary of the number of elements of each size is printed out by
node zero.

@<Sparse matrix public routines.@>=
GLOBAL_FUNCTION void
dmt_sparsity(mat)
mdescr mat;
{
  char *dmt_title();
  int slot;
  int nlocal = dmt_nlocal(mat);
  int size = dmt_size(mat);
  int dist = dmt_distribution(mat);
  int i, j, iind, jind, isz, jsz;
  int n_elements[MAX_ELEMENTS];
  double *data;

  for (i=0; i<MAX_ELEMENTS; i++) {
    n_elements[i] = 0;
    }

  for (i=0; i<nlocal; i++) {

    /* Get the locally held data and compute the size if necessary. */
    if (dist == COLUMNS) {
      dmt_get_col(mat,i,&iind,&data);
      /* The size of column matrices is computed above. */
      }
    else if (dist == SCATTERED) {
      dmt_get_block_dsc(mat,i,&iind,&isz,&jind,&jsz,&data);
      size = isz * jsz;
      }

    /* Increment the appropriate $n_{elements}$ slot. */
    for (j=0; j<size; j++) {
      if (data[j] == 0.0) slot = ELEMENT_START;
      else slot = floor(log10(fabs(data[j])));
      slot -= ELEMENT_START;
      if (slot < 0) slot = 0;
      else if (slot >= MAX_ELEMENTS) slot = MAX_ELEMENTS - 1;
      n_elements[slot]++;
      }
    }

  /* Globally sum the $n_{elements}$ arrays. */
  gsum0(n_elements,MAX_ELEMENTS,2,mtype_get(),0);

  /* Print out the $n_{elements}$ array on node 0. */
  if (mynode0() == 0) {
    int ii;
    int total=0;
    printf("Sparsity information for \"%s\"\n",dmt_title(mat));
    j = ELEMENT_START;
    for (ii=0; ii<MAX_ELEMENTS; ii+=10) {
      int iend = ii + 10;
      if (iend > MAX_ELEMENTS) iend = MAX_ELEMENTS;
      for (i=ii; i<iend; i++) printf(" %5d ",j++);
      printf("\n");
      for (i=ii; i<iend; i++) {
        printf(" %6d",n_elements[i]);
        total += n_elements[i];
        }
      printf("\n");
      }
    printf(" Total elements %d\n", total);
    }
  }

